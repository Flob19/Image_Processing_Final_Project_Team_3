{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:18.768101Z",
     "iopub.status.busy": "2025-12-12T05:32:18.767867Z",
     "iopub.status.idle": "2025-12-12T05:32:19.889980Z",
     "shell.execute_reply": "2025-12-12T05:32:19.889278Z",
     "shell.execute_reply.started": "2025-12-12T05:32:18.768083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall \"protobuf==3.20.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:19.891095Z",
     "iopub.status.busy": "2025-12-12T05:32:19.890871Z",
     "iopub.status.idle": "2025-12-12T05:32:19.957805Z",
     "shell.execute_reply": "2025-12-12T05:32:19.957076Z",
     "shell.execute_reply.started": "2025-12-12T05:32:19.891075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Super-Resolution Project\n",
    "- SRCNN baseline (PSNR-oriented)\n",
    "- SRGAN baseline (SRResNet + BCE + VGG content)\n",
    "- Attentive ESRGAN (no BN, channel attention, RaLSGAN + VGG + L1)\n",
    "\n",
    "Paste this into a Kaggle notebook cell and run it once to define everything.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# 0. Imports & Global Config\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:19.959523Z",
     "iopub.status.busy": "2025-12-12T05:32:19.959274Z",
     "iopub.status.idle": "2025-12-12T05:32:19.963655Z",
     "shell.execute_reply": "2025-12-12T05:32:19.962846Z",
     "shell.execute_reply.started": "2025-12-12T05:32:19.959507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------------- Configuration ----------------\n",
    "\n",
    "# DIV2K root (adjust these paths for your environment)\n",
    "DIV2K_ROOT = \"/kaggle/input/div2k-high-resolution-images\"\n",
    "\n",
    "# Example pre-trained model paths (for Kaggle; change for your setup)\n",
    "SRCNN_PRETRAINED_PATH = \"/kaggle/input/my-sr-models/srcnn_baseline_model.h5\"\n",
    "SRRESNET_WARMUP_PATH = \"/kaggle/input/my-sr-models/srresnet_warmup.h5\"\n",
    "ATTENTIVE_WARMUP_PATH = \"/kaggle/input/my-sr-models/attentive_generator_warmup.h5\"\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "HR_CROP_SIZE = 128\n",
    "UPSCALE = 4\n",
    "LR_CROP_SIZE = HR_CROP_SIZE // UPSCALE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pipeline for SRGAN / ESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:19.964827Z",
     "iopub.status.busy": "2025-12-12T05:32:19.964466Z",
     "iopub.status.idle": "2025-12-12T05:32:20.012983Z",
     "shell.execute_reply": "2025-12-12T05:32:20.012273Z",
     "shell.execute_reply.started": "2025-12-12T05:32:19.964810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRGANDataGenerator] 800 images found in: /kaggle/input/div2k-high-resolution-images/DIV2K_train_HR/DIV2K_train_HR\n",
      "[SRGANDataGenerator] 100 images found in: /kaggle/input/div2k-high-resolution-images/DIV2K_valid_HR/DIV2K_valid_HR\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Data Pipeline for SRGAN / ESRGAN\n",
    "# ============================================================\n",
    "\n",
    "class SRGANDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom Data Generator for Super Resolution (SRGAN / ESRGAN).\n",
    "    - Loads HR images from a folder\n",
    "    - Random crops HR patches of size HR_CROP_SIZE x HR_CROP_SIZE\n",
    "    - Generates LR patches via bicubic downsampling\n",
    "    - Normalizes both LR & HR to [-1, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_dir, batch_size=16, crop_size=128, scale_factor=4, shuffle=True):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.crop_size = crop_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        try:\n",
    "            self.image_files = sorted(\n",
    "                f for f in os.listdir(hr_dir)\n",
    "                if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "            )\n",
    "            print(f\"[SRGANDataGenerator] {len(self.image_files)} images found in: {hr_dir}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[SRGANDataGenerator] ERROR: Directory not found: {hr_dir}\")\n",
    "            self.image_files = []\n",
    "\n",
    "        self.indexes = np.arange(len(self.image_files))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.image_files:\n",
    "            return 0\n",
    "        return math.ceil(len(self.image_files) / self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = (index + 1) * self.batch_size\n",
    "        batch_indexes = self.indexes[start:end]\n",
    "        batch_files = [self.image_files[i] for i in batch_indexes]\n",
    "\n",
    "        lr_batch, hr_batch = [], []\n",
    "\n",
    "        for fname in batch_files:\n",
    "            img_path = os.path.join(self.hr_dir, fname)\n",
    "            try:\n",
    "                hr_img = cv2.imread(img_path)\n",
    "                if hr_img is None:\n",
    "                    continue\n",
    "                hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                h, w, _ = hr_img.shape\n",
    "                if h < self.crop_size or w < self.crop_size:\n",
    "                    continue\n",
    "\n",
    "                # Random HR crop\n",
    "                x = random.randint(0, w - self.crop_size)\n",
    "                y = random.randint(0, h - self.crop_size)\n",
    "                hr_patch = hr_img[y:y + self.crop_size, x:x + self.crop_size]\n",
    "\n",
    "                # LR via bicubic downsampling\n",
    "                lr_size = (self.crop_size // self.scale_factor,\n",
    "                           self.crop_size // self.scale_factor)\n",
    "                lr_patch = cv2.resize(hr_patch, lr_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                # Normalize to [-1, 1]\n",
    "                lr_batch.append(lr_patch / 127.5 - 1.0)\n",
    "                hr_batch.append(hr_patch / 127.5 - 1.0)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[SRGANDataGenerator] Error processing {fname}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if len(lr_batch) == 0:\n",
    "            # fallback to next batch if something went wrong\n",
    "            return self.__getitem__((index + 1) % self.__len__())\n",
    "\n",
    "        return np.array(lr_batch), np.array(hr_batch)\n",
    "\n",
    "\n",
    "def resolve_div2k_paths(root):\n",
    "    \"\"\"\n",
    "    Handle possible nested structures in Kaggle DIV2K dataset.\n",
    "    Returns (train_hr_dir, valid_hr_dir).\n",
    "    \"\"\"\n",
    "    train = os.path.join(root, \"DIV2K_train_HR\", \"DIV2K_train_HR\")\n",
    "    valid = os.path.join(root, \"DIV2K_valid_HR\", \"DIV2K_valid_HR\")\n",
    "    if not os.path.exists(train):\n",
    "        train = os.path.join(root, \"DIV2K_train_HR\")\n",
    "        valid = os.path.join(root, \"DIV2K_valid_HR\")\n",
    "    return train, valid\n",
    "\n",
    "\n",
    "# Prepare generators (you can comment these out and call later if you want)\n",
    "train_hr_dir, valid_hr_dir = resolve_div2k_paths(DIV2K_ROOT)\n",
    "train_gen = SRGANDataGenerator(train_hr_dir, batch_size=BATCH_SIZE,\n",
    "                               crop_size=HR_CROP_SIZE, scale_factor=UPSCALE)\n",
    "val_gen = SRGANDataGenerator(valid_hr_dir, batch_size=BATCH_SIZE,\n",
    "                             crop_size=HR_CROP_SIZE, scale_factor=UPSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SRCNN Baseline (PSNR-oriented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:20.014224Z",
     "iopub.status.busy": "2025-12-12T05:32:20.013764Z",
     "iopub.status.idle": "2025-12-12T05:32:20.024020Z",
     "shell.execute_reply": "2025-12-12T05:32:20.023312Z",
     "shell.execute_reply.started": "2025-12-12T05:32:20.014200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRCNN helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. SRCNN Baseline (PSNR-oriented)\n",
    "# ============================================================\n",
    "\n",
    "def build_srcnn():\n",
    "    \"\"\"\n",
    "    SRCNN architecture (3 conv layers):\n",
    "    - Conv 64 @ 9x9\n",
    "    - Conv 32 @ 1x1\n",
    "    - Conv 3  @ 5x5\n",
    "    Input/Output: RGB in [0,1].\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (9, 9), activation='relu', padding='same',\n",
    "                      input_shape=(None, None, 3)),\n",
    "        layers.Conv2D(32, (1, 1), activation='relu', padding='same'),\n",
    "        layers.Conv2D(3, (5, 5), activation='linear', padding='same'),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_srcnn_full_image(model, image_path, scale_factor=4):\n",
    "    \"\"\"\n",
    "    Evaluate SRCNN on a full-resolution image (baseline PSNR model).\n",
    "    Steps:\n",
    "        HR -> downscale (LR) -> bicubic upsample -> SRCNN -> compare to HR\n",
    "    Everything is in [0,1] for SRCNN.\n",
    "    \"\"\"\n",
    "    hr_img = cv2.imread(image_path)\n",
    "    if hr_img is None:\n",
    "        print(f\"[SRCNN] Could not load image: {image_path}\")\n",
    "        return\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = hr_img.shape\n",
    "    h, w = (h // scale_factor) * scale_factor, (w // scale_factor) * scale_factor\n",
    "    hr_img = hr_img[:h, :w, :]\n",
    "\n",
    "    lr_shape = (w // scale_factor, h // scale_factor)\n",
    "    lr_img_small = cv2.resize(hr_img, lr_shape, interpolation=cv2.INTER_CUBIC)\n",
    "    lr_up = cv2.resize(lr_img_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # SRCNN input: [0,1]\n",
    "    inp = lr_up.astype(np.float32) / 255.0\n",
    "    inp_batch = np.expand_dims(inp, axis=0)\n",
    "\n",
    "    sr_img = model.predict(inp_batch, verbose=0)[0]\n",
    "    sr_img = np.clip(sr_img, 0.0, 1.0)\n",
    "\n",
    "    hr_img_01 = hr_img.astype(np.float32) / 255.0\n",
    "    bicubic_img = lr_up.astype(np.float32) / 255.0\n",
    "\n",
    "    tf_hr = tf.convert_to_tensor(hr_img_01, tf.float32)\n",
    "    tf_sr = tf.convert_to_tensor(sr_img, tf.float32)\n",
    "    tf_bic = tf.convert_to_tensor(bicubic_img, tf.float32)\n",
    "\n",
    "    psnr_sr = tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "    psnr_bic = tf.image.psnr(tf_hr, tf_bic, max_val=1.0).numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 10))\n",
    "    axes[0].imshow(bicubic_img)\n",
    "    axes[0].set_title(f\"Bicubic\\nPSNR: {psnr_bic:.2f} dB\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sr_img)\n",
    "    axes[1].set_title(\n",
    "        f\"SRCNN\\nPSNR: {psnr_sr:.2f} dB\",\n",
    "        color=\"green\" if psnr_sr > psnr_bic else \"black\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(hr_img_01)\n",
    "    axes[2].set_title(\"Ground Truth\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"SRCNN helpers defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SRGAN Baseline (SRResNet + BCE + VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:32:20.025670Z",
     "iopub.status.busy": "2025-12-12T05:32:20.025465Z",
     "iopub.status.idle": "2025-12-12T05:32:20.054580Z",
     "shell.execute_reply": "2025-12-12T05:32:20.053928Z",
     "shell.execute_reply.started": "2025-12-12T05:32:20.025647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRGAN baseline models & helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. SRGAN Baseline (SRResNet + BCE + VGG)\n",
    "# ============================================================\n",
    "\n",
    "def residual_block_bn(x):\n",
    "    \"\"\"\n",
    "    Residual block with BatchNorm (original SRGAN).\n",
    "    Conv -> BN -> PReLU -> Conv -> BN -> Add.\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    return layers.Add()([x, shortcut])\n",
    "\n",
    "\n",
    "def upsample_block_bn(x):\n",
    "    \"\"\"\n",
    "    Upsample block with BN-based generator (PixelShuffle x2).\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "    x = layers.Lambda(lambda z: tf.nn.depth_to_space(z, block_size=2))(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_srgan_generator(scale=4, num_res_blocks=16):\n",
    "    \"\"\"\n",
    "    Baseline SRGAN generator (SRResNet) with BN in residual blocks.\n",
    "    Output: tanh in [-1,1].\n",
    "    \"\"\"\n",
    "    lr_input = Input(shape=(None, None, 3))\n",
    "\n",
    "    x1 = layers.Conv2D(64, 9, padding='same')(lr_input)\n",
    "    x1 = layers.PReLU(shared_axes=[1, 2])(x1)\n",
    "\n",
    "    x = x1\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = residual_block_bn(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.Add()([x, x1])\n",
    "\n",
    "    if scale >= 2:\n",
    "        x = upsample_block_bn(x)\n",
    "    if scale >= 4:\n",
    "        x = upsample_block_bn(x)\n",
    "\n",
    "    out = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n",
    "    return models.Model(lr_input, out, name=\"SRGAN_Generator\")\n",
    "\n",
    "\n",
    "def discriminator_block(x, filters, strides=1, batch_norm=True):\n",
    "    x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_srgan_discriminator(input_shape):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    x = discriminator_block(img_input, 64, strides=1, batch_norm=False)\n",
    "    x = discriminator_block(x, 64, strides=2)\n",
    "    x = discriminator_block(x, 128, strides=1)\n",
    "    x = discriminator_block(x, 128, strides=2)\n",
    "    x = discriminator_block(x, 256, strides=1)\n",
    "    x = discriminator_block(x, 256, strides=2)\n",
    "    x = discriminator_block(x, 512, strides=1)\n",
    "    x = discriminator_block(x, 512, strides=2)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    validity = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return models.Model(img_input, validity, name=\"SRGAN_Discriminator\")\n",
    "\n",
    "\n",
    "def build_vgg(hr_shape):\n",
    "    vgg = VGG19(weights=\"imagenet\", include_top=False, input_shape=hr_shape)\n",
    "    model = models.Model(\n",
    "        inputs=vgg.inputs,\n",
    "        outputs=vgg.get_layer(\"block5_conv4\").output\n",
    "    )\n",
    "    model.trainable = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_srgan_combined(generator, discriminator, vgg, lr_shape):\n",
    "    # freeze D + VGG chỉ cho combined\n",
    "    discriminator.trainable = False\n",
    "    for l in discriminator.layers: \n",
    "        l.trainable = False\n",
    "\n",
    "    vgg.trainable = False\n",
    "    for l in vgg.layers:\n",
    "        l.trainable = False\n",
    "\n",
    "    lr_input = Input(shape=lr_shape)\n",
    "    sr = generator(lr_input)\n",
    "    sr_features = vgg(sr)\n",
    "    validity = discriminator(sr)\n",
    "\n",
    "    model = models.Model(lr_input, [validity, sr_features])\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'mse'],\n",
    "        loss_weights=[1e-3, 1.0],\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: bật lại D để bạn còn train D riêng\n",
    "    discriminator.trainable = True\n",
    "    for l in discriminator.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def train_srgan_baseline(generator,\n",
    "                         discriminator,\n",
    "                         srgan,\n",
    "                         vgg,\n",
    "                         train_loader,\n",
    "                         val_loader=None,\n",
    "                         epochs=30,\n",
    "                         steps_per_epoch=50):\n",
    "    \"\"\"\n",
    "    Classical SRGAN training:\n",
    "      - D: BCE on real/fake HR images\n",
    "      - G: combined model with BCE (fool D) + VGG MSE (content)\n",
    "\n",
    "    Returns:\n",
    "        history: dict with per-epoch averages:\n",
    "            - 'epoch'\n",
    "            - 'd_loss'\n",
    "            - 'g_loss'\n",
    "            - 'val_psnr' (if val_loader given)\n",
    "            - 'val_ssim' (if val_loader given)\n",
    "    \"\"\"\n",
    "    batch_size = BATCH_SIZE\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"d_loss\": [],\n",
    "        \"g_loss\": [],\n",
    "    }\n",
    "    if val_loader is not None:\n",
    "        history[\"val_psnr\"] = []\n",
    "        history[\"val_ssim\"] = []\n",
    "\n",
    "    print(\"[SRGAN] Starting training...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        d_losses, g_losses = [], []\n",
    "        start = time.time()\n",
    "\n",
    "        for step in range(steps_per_epoch):\n",
    "            try:\n",
    "                lr_imgs, hr_imgs = train_loader.__getitem__(step % len(train_loader))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if len(lr_imgs) != batch_size:\n",
    "                continue\n",
    "\n",
    "            # ---------- Train Discriminator ----------\n",
    "            fake_imgs = generator.predict(lr_imgs, verbose=0)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(hr_imgs, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_labels)\n",
    "\n",
    "            d_real_val = d_loss_real[0] if isinstance(d_loss_real, list) else d_loss_real\n",
    "            d_fake_val = d_loss_fake[0] if isinstance(d_loss_fake, list) else d_loss_fake\n",
    "            d_loss = 0.5 * (d_real_val + d_fake_val)\n",
    "            d_losses.append(d_loss)\n",
    "\n",
    "            # ---------- Train Generator ----------\n",
    "            hr_features = vgg.predict(hr_imgs, verbose=0)\n",
    "            g_loss = srgan.train_on_batch(lr_imgs, [real_labels, hr_features])\n",
    "            g_total = g_loss[0] if isinstance(g_loss, list) else g_loss\n",
    "            g_losses.append(g_total)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f\"[SRGAN] Epoch {epoch+1}/{epochs} \"\n",
    "                      f\"Step {step}/{steps_per_epoch} | D: {d_loss:.4f} | G: {g_total:.4f}\")\n",
    "\n",
    "        # ---- End of epoch: aggregate ----\n",
    "        avg_d = float(np.mean(d_losses)) if d_losses else np.nan\n",
    "        avg_g = float(np.mean(g_losses)) if g_losses else np.nan\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"d_loss\"].append(avg_d)\n",
    "        history[\"g_loss\"].append(avg_g)\n",
    "\n",
    "        # ---- Optional: validation PSNR / SSIM on a few batches ----\n",
    "        if val_loader is not None and len(val_loader) > 0:\n",
    "            val_psnrs, val_ssims = [], []\n",
    "            # only a few batches to keep it cheap\n",
    "            num_val_batches = min(3, len(val_loader))\n",
    "            for i in range(num_val_batches):\n",
    "                try:\n",
    "                    lr_val, hr_val = val_loader.__getitem__(i)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if len(lr_val) == 0:\n",
    "                    continue\n",
    "\n",
    "                # G expects [-1,1], so lr_val is already [-1,1] from generator\n",
    "                sr_val = generator.predict(lr_val, verbose=0)\n",
    "                # Convert to [0,1]\n",
    "                hr_01 = (hr_val + 1.0) / 2.0\n",
    "                sr_01 = (sr_val + 1.0) / 2.0\n",
    "                hr_01 = np.clip(hr_01, 0.0, 1.0)\n",
    "                sr_01 = np.clip(sr_01, 0.0, 1.0)\n",
    "\n",
    "                # Compute PSNR / SSIM per image, then average\n",
    "                for h_im, s_im in zip(hr_01, sr_01):\n",
    "                    tf_hr = tf.convert_to_tensor(h_im, tf.float32)\n",
    "                    tf_sr = tf.convert_to_tensor(s_im, tf.float32)\n",
    "                    val_psnrs.append(tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy())\n",
    "                    val_ssims.append(tf.image.ssim(tf_hr, tf_sr, max_val=1.0).numpy())\n",
    "\n",
    "            if val_psnrs:\n",
    "                history[\"val_psnr\"].append(float(np.mean(val_psnrs)))\n",
    "                history[\"val_ssim\"].append(float(np.mean(val_ssims)))\n",
    "                print(f\"[SRGAN] Epoch {epoch+1} VAL | \"\n",
    "                      f\"PSNR: {history['val_psnr'][-1]:.2f} dB | \"\n",
    "                      f\"SSIM: {history['val_ssim'][-1]:.4f}\")\n",
    "            else:\n",
    "                history[\"val_psnr\"].append(np.nan)\n",
    "                history[\"val_ssim\"].append(np.nan)\n",
    "\n",
    "        print(f\"[SRGAN] Epoch {epoch+1} done in {time.time()-start:.1f}s \"\n",
    "              f\"| D: {avg_d:.4f} | G: {avg_g:.4f}\")\n",
    "        generator.save(f\"srgan_generator_epoch_{epoch+1}.keras\")\n",
    "\n",
    "    print(\"[SRGAN] Training complete.\")\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def predict_srgan_full_image(generator, image_path, scale_factor=4):\n",
    "    \"\"\"\n",
    "    Evaluate SRGAN baseline on a full image.\n",
    "    Generator expects LR in [-1,1] and outputs SR in [-1,1].\n",
    "    \"\"\"\n",
    "    hr_img = cv2.imread(image_path)\n",
    "    if hr_img is None:\n",
    "        print(f\"[SRGAN] Could not load image: {image_path}\")\n",
    "        return\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = hr_img.shape\n",
    "    h, w = (h // scale_factor) * scale_factor, (w // scale_factor) * scale_factor\n",
    "    hr_img = hr_img[:h, :w, :]\n",
    "\n",
    "    lr_shape = (w // scale_factor, h // scale_factor)\n",
    "    lr_img_small = cv2.resize(hr_img, lr_shape, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Normalize to [-1,1] for generator\n",
    "    lr_input_01 = lr_img_small.astype(np.float32) / 255.0\n",
    "    lr_input = lr_input_01 * 2.0 - 1.0\n",
    "    inp_batch = np.expand_dims(lr_input, axis=0)\n",
    "\n",
    "    sr = generator.predict(inp_batch, verbose=0)[0]        # [-1,1]\n",
    "    sr_01 = (sr + 1.0) / 2.0                               # [0,1]\n",
    "    sr_01 = np.clip(sr_01, 0.0, 1.0)\n",
    "\n",
    "    bicubic = cv2.resize(lr_img_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    bicubic = bicubic.astype(np.float32) / 255.0\n",
    "\n",
    "    hr_01 = hr_img.astype(np.float32) / 255.0\n",
    "\n",
    "    tf_hr = tf.convert_to_tensor(hr_01, tf.float32)\n",
    "    tf_sr = tf.convert_to_tensor(sr_01, tf.float32)\n",
    "    tf_bic = tf.convert_to_tensor(bicubic, tf.float32)\n",
    "\n",
    "    psnr_sr = tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "    ssim_sr = tf.image.ssim(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "    psnr_bic = tf.image.psnr(tf_hr, tf_bic, max_val=1.0).numpy()\n",
    "    ssim_bic = tf.image.ssim(tf_hr, tf_bic, max_val=1.0).numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 10))\n",
    "    axes[0].imshow(bicubic)\n",
    "    axes[0].set_title(f\"Bicubic\\nPSNR: {psnr_bic:.2f} dB | SSIM: {ssim_bic:.4f}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sr_01)\n",
    "    title_col = \"green\" if psnr_sr > psnr_bic else \"black\"\n",
    "    axes[1].set_title(f\"SRGAN\\nPSNR: {psnr_sr:.2f} dB | SSIM: {ssim_sr:.4f}\",\n",
    "                      color=title_col, fontweight=\"bold\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(hr_01)\n",
    "    axes[2].set_title(\"Ground Truth\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"SRGAN baseline models & helpers defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-12T05:46:41.169439Z",
     "iopub.status.idle": "2025-12-12T05:46:41.169657Z",
     "shell.execute_reply": "2025-12-12T05:46:41.169563Z",
     "shell.execute_reply.started": "2025-12-12T05:46:41.169553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "srgan_gen = build_srgan_generator(scale=UPSCALE, num_res_blocks=16)\n",
    "srgan_gen.load_weights(SRRESNET_WARMUP_PATH)\n",
    "srgan_disc = build_srgan_discriminator(input_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "vgg = build_vgg(hr_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "\n",
    "srgan_disc.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "srgan_combined = build_srgan_combined(\n",
    "    srgan_gen, srgan_disc, vgg,\n",
    "    lr_shape=(LR_CROP_SIZE, LR_CROP_SIZE, 3)\n",
    ")\n",
    "\n",
    "srgan_history = train_srgan_baseline(\n",
    "    generator=srgan_gen,\n",
    "    discriminator=srgan_disc,\n",
    "    srgan=srgan_combined,\n",
    "    vgg=vgg,\n",
    "    train_loader=train_gen,\n",
    "    val_loader=val_gen,      # can be None if you don't want val metrics\n",
    "    epochs=30,\n",
    "    steps_per_epoch=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Attentive ESRGAN (No BN, Channel Attention, RaLSGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:47:12.232867Z",
     "iopub.status.busy": "2025-12-12T05:47:12.232278Z",
     "iopub.status.idle": "2025-12-12T05:47:12.263920Z",
     "shell.execute_reply": "2025-12-12T05:47:12.263146Z",
     "shell.execute_reply.started": "2025-12-12T05:47:12.232838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attentive ESRGAN models & helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. Attentive ESRGAN (No BN, Channel Attention, RaLSGAN)\n",
    "# ============================================================\n",
    "\n",
    "def channel_attention_block(x, ratio=16):\n",
    "    channels = x.shape[-1]\n",
    "    if channels is None:\n",
    "        channels = 64  # safe fallback for this architecture\n",
    "\n",
    "    se = layers.GlobalAveragePooling2D(keepdims=True)(x)\n",
    "    reduced_channels = max(int(channels) // ratio, 1)\n",
    "    se = layers.Dense(reduced_channels, activation='relu', use_bias=False)(se)\n",
    "    se = layers.Dense(int(channels), activation='sigmoid', use_bias=False)(se)\n",
    "    return layers.Multiply()([x, se])\n",
    "\n",
    "\n",
    "class PixelShuffle(layers.Layer):\n",
    "    def __init__(self, scale=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale = scale\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depth_to_space(inputs, block_size=self.scale)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\"scale\": self.scale})\n",
    "        return cfg\n",
    "\n",
    "\n",
    "# def attentive_residual_block(x):\n",
    "#     shortcut = x\n",
    "\n",
    "#     x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "#     x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "#     x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "#     x = channel_attention_block(x)\n",
    "\n",
    "#     # residual scaling 0.2, no Lambda\n",
    "#     x = layers.Multiply()([x, tf.constant(0.2, dtype=tf.float32)])\n",
    "#     return layers.Add()([x, shortcut])\n",
    "\n",
    "def attentive_residual_block(x):\n",
    "    shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = channel_attention_block(x)\n",
    "\n",
    "    # residual scaling 0.2 — just use tensor math\n",
    "    x = x * 0.2\n",
    "\n",
    "    return layers.Add()([x, shortcut])\n",
    "\n",
    "def upsample_block_no_bn(x, scale=2):\n",
    "    # 64 * scale^2 filters -> after pixel shuffle we still have 64 channels\n",
    "    x = layers.Conv2D(64 * (scale ** 2), 3, padding='same')(x)\n",
    "    x = PixelShuffle(scale)(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_attentive_generator(scale=4, num_res_blocks=16):\n",
    "    lr_input = Input(shape=(None, None, 3))\n",
    "\n",
    "    x1 = layers.Conv2D(64, 9, padding='same')(lr_input)\n",
    "    x1 = layers.PReLU(shared_axes=[1, 2])(x1)\n",
    "\n",
    "    x = x1\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = attentive_residual_block(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.Add()([x, x1])\n",
    "\n",
    "    if scale >= 2:\n",
    "        x = upsample_block_no_bn(x, scale=2)\n",
    "    if scale >= 4:\n",
    "        x = upsample_block_no_bn(x, scale=2)\n",
    "\n",
    "    out = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n",
    "    return models.Model(lr_input, out, name=\"Attentive_Generator\")\n",
    "\n",
    "\n",
    "def build_relativistic_discriminator(input_shape):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    def d_block(x, filters, strides=1, bn=True):\n",
    "        x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "        if bn:\n",
    "            x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        return x\n",
    "\n",
    "    x = d_block(img_input, 64, strides=1, bn=False)\n",
    "    x = d_block(x, 64, strides=2)\n",
    "    x = d_block(x, 128, strides=1)\n",
    "    x = d_block(x, 128, strides=2)\n",
    "    x = d_block(x, 256, strides=1)\n",
    "    x = d_block(x, 256, strides=2)\n",
    "    x = d_block(x, 512, strides=1)\n",
    "    x = d_block(x, 512, strides=2)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    validity = layers.Dense(1)(x)  # logits\n",
    "    return models.Model(img_input, validity, name=\"Relativistic_Discriminator\")\n",
    "\n",
    "def train_attentive_esrgan(generator,\n",
    "                           discriminator,\n",
    "                           vgg,\n",
    "                           train_loader,\n",
    "                           val_loader=None,\n",
    "                           epochs=30,\n",
    "                           steps_per_epoch=50):\n",
    "    \"\"\"\n",
    "    ESRGAN-style training:\n",
    "      - RaLSGAN adversarial loss\n",
    "      - VGG19 perceptual loss\n",
    "      - L1 pixel loss\n",
    "\n",
    "    Returns:\n",
    "        history dict with:\n",
    "            - 'epoch'\n",
    "            - 'd_loss'\n",
    "            - 'g_loss'\n",
    "            - 'val_psnr' (optional)\n",
    "            - 'val_ssim' (optional)\n",
    "    \"\"\"\n",
    "    g_opt = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    d_opt = keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    mse = keras.losses.MeanSquaredError()\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"d_loss\": [],\n",
    "        \"g_loss\": [],\n",
    "    }\n",
    "    if val_loader is not None:\n",
    "        history[\"val_psnr\"] = []\n",
    "        history[\"val_ssim\"] = []\n",
    "\n",
    "    print(\"[Attentive ESRGAN] Starting training (RaLSGAN)...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        epoch_d_losses, epoch_g_losses = [], []\n",
    "\n",
    "        for step in range(steps_per_epoch):\n",
    "            try:\n",
    "                lr_imgs, hr_imgs = train_loader.__getitem__(step % len(train_loader))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if len(lr_imgs) != BATCH_SIZE:\n",
    "                continue\n",
    "\n",
    "            # -------- Train Discriminator --------\n",
    "            with tf.GradientTape() as tape_d:\n",
    "                fake_imgs = generator(lr_imgs, training=True)\n",
    "\n",
    "                real_logits = discriminator(hr_imgs, training=True)\n",
    "                fake_logits = discriminator(fake_imgs, training=True)\n",
    "\n",
    "                mean_fake = tf.reduce_mean(fake_logits, axis=0, keepdims=True)\n",
    "                mean_real = tf.reduce_mean(real_logits, axis=0, keepdims=True)\n",
    "\n",
    "                real_rel = real_logits - mean_fake\n",
    "                fake_rel = fake_logits - mean_real\n",
    "\n",
    "                d_loss_real = tf.reduce_mean((real_rel - 1.0) ** 2)\n",
    "                d_loss_fake = tf.reduce_mean((fake_rel + 1.0) ** 2)\n",
    "                d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "            d_grads = tape_d.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "            epoch_d_losses.append(d_loss.numpy())\n",
    "\n",
    "            # -------- Train Generator --------\n",
    "            with tf.GradientTape() as tape_g:\n",
    "                fake_imgs = generator(lr_imgs, training=True)\n",
    "\n",
    "                real_logits = discriminator(hr_imgs, training=False)\n",
    "                fake_logits = discriminator(fake_imgs, training=False)\n",
    "\n",
    "                mean_fake = tf.reduce_mean(fake_logits, axis=0, keepdims=True)\n",
    "                mean_real = tf.reduce_mean(real_logits, axis=0, keepdims=True)\n",
    "\n",
    "                real_rel = real_logits - mean_fake\n",
    "                fake_rel = fake_logits - mean_real\n",
    "\n",
    "                g_loss_real = tf.reduce_mean((real_rel + 1.0) ** 2)\n",
    "                g_loss_fake = tf.reduce_mean((fake_rel - 1.0) ** 2)\n",
    "                adv_loss = 0.5 * (g_loss_real + g_loss_fake)\n",
    "\n",
    "                # VGG perceptual loss\n",
    "                hr_vgg = preprocess_input((hr_imgs + 1.0) * 127.5)\n",
    "                fake_vgg = preprocess_input((fake_imgs + 1.0) * 127.5)\n",
    "                img_features = vgg(hr_vgg, training=False)\n",
    "                gen_features = vgg(fake_vgg, training=False)\n",
    "                content_loss = mse(img_features, gen_features)\n",
    "\n",
    "                # L1 pixel loss\n",
    "                pixel_loss = tf.reduce_mean(tf.abs(hr_imgs - fake_imgs))\n",
    "\n",
    "                total_g_loss = (0.006 * content_loss) + (5e-3 * adv_loss) + (1e-2 * pixel_loss)\n",
    "\n",
    "            g_grads = tape_g.gradient(total_g_loss, generator.trainable_variables)\n",
    "            g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "            epoch_g_losses.append(total_g_loss.numpy())\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f\"[Attentive ESRGAN] Epoch {epoch+1}/{epochs} \"\n",
    "                      f\"Step {step}/{steps_per_epoch} | \"\n",
    "                      f\"D: {d_loss.numpy():.4f} | G: {total_g_loss.numpy():.4f}\")\n",
    "\n",
    "        # ---- end epoch: aggregate ----\n",
    "        avg_d = float(np.mean(epoch_d_losses)) if epoch_d_losses else np.nan\n",
    "        avg_g = float(np.mean(epoch_g_losses)) if epoch_g_losses else np.nan\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"d_loss\"].append(avg_d)\n",
    "        history[\"g_loss\"].append(avg_g)\n",
    "\n",
    "        # ---- optional validation metrics ----\n",
    "        if val_loader is not None and len(val_loader) > 0:\n",
    "            val_psnrs, val_ssims = [], []\n",
    "            num_val_batches = min(3, len(val_loader))\n",
    "            for i in range(num_val_batches):\n",
    "                try:\n",
    "                    lr_val, hr_val = val_loader.__getitem__(i)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if len(lr_val) == 0:\n",
    "                    continue\n",
    "\n",
    "                sr_val = generator.predict(lr_val, verbose=0)\n",
    "                hr_01 = (hr_val + 1.0) / 2.0\n",
    "                sr_01 = (sr_val + 1.0) / 2.0\n",
    "                hr_01 = np.clip(hr_01, 0.0, 1.0)\n",
    "                sr_01 = np.clip(sr_01, 0.0, 1.0)\n",
    "\n",
    "                for h_im, s_im in zip(hr_01, sr_01):\n",
    "                    tf_hr = tf.convert_to_tensor(h_im, tf.float32)\n",
    "                    tf_sr = tf.convert_to_tensor(s_im, tf.float32)\n",
    "                    val_psnrs.append(tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy())\n",
    "                    val_ssims.append(tf.image.ssim(tf_hr, tf_sr, max_val=1.0).numpy())\n",
    "\n",
    "            if val_psnrs:\n",
    "                history[\"val_psnr\"].append(float(np.mean(val_psnrs)))\n",
    "                history[\"val_ssim\"].append(float(np.mean(val_ssims)))\n",
    "                print(f\"[Attentive ESRGAN] Epoch {epoch+1} VAL | \"\n",
    "                      f\"PSNR: {history['val_psnr'][-1]:.2f} dB | \"\n",
    "                      f\"SSIM: {history['val_ssim'][-1]:.4f}\")\n",
    "            else:\n",
    "                history[\"val_psnr\"].append(np.nan)\n",
    "                history[\"val_ssim\"].append(np.nan)\n",
    "\n",
    "        generator.save(f\"attentive_esrgan_epoch_{epoch+1}.keras\")\n",
    "        print(f\"[Attentive ESRGAN] Epoch {epoch+1} done in {time.time()-start:.1f}s | \"\n",
    "              f\"D: {avg_d:.4f} | G: {avg_g:.4f}\")\n",
    "\n",
    "    print(\"[Attentive ESRGAN] Training complete.\")\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def predict_attentive_full_image(generator, image_path, scale_factor=4):\n",
    "    \"\"\"\n",
    "    Evaluate Attentive ESRGAN on a full image.\n",
    "    Same normalization as SRGAN baseline: [-1,1] in, tanh output.\n",
    "    \"\"\"\n",
    "    hr_img = cv2.imread(image_path)\n",
    "    if hr_img is None:\n",
    "        print(f\"[Attentive ESRGAN] Could not load image: {image_path}\")\n",
    "        return\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = hr_img.shape\n",
    "    h, w = (h // scale_factor) * scale_factor, (w // scale_factor) * scale_factor\n",
    "    hr_img = hr_img[:h, :w, :]\n",
    "\n",
    "    lr_shape = (w // scale_factor, h // scale_factor)\n",
    "    lr_img_small = cv2.resize(hr_img, lr_shape, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    lr_01 = lr_img_small.astype(np.float32) / 255.0\n",
    "    lr_in = lr_01 * 2.0 - 1.0\n",
    "    inp_batch = np.expand_dims(lr_in, axis=0)\n",
    "\n",
    "    sr = generator.predict(inp_batch, verbose=0)[0]   # [-1,1]\n",
    "    sr_01 = (sr + 1.0) / 2.0\n",
    "    sr_01 = np.clip(sr_01, 0.0, 1.0)\n",
    "\n",
    "    bicubic = cv2.resize(lr_img_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    bicubic = bicubic.astype(np.float32) / 255.0\n",
    "    hr_01 = hr_img.astype(np.float32) / 255.0\n",
    "\n",
    "    tf_hr = tf.convert_to_tensor(hr_01, tf.float32)\n",
    "    tf_sr = tf.convert_to_tensor(sr_01, tf.float32)\n",
    "    tf_bic = tf.convert_to_tensor(bicubic, tf.float32)\n",
    "\n",
    "    psnr_sr = tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "    ssim_sr = tf.image.ssim(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "    psnr_bic = tf.image.psnr(tf_hr, tf_bic, max_val=1.0).numpy()\n",
    "    ssim_bic = tf.image.ssim(tf_hr, tf_bic, max_val=1.0).numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 10))\n",
    "    axes[0].imshow(bicubic)\n",
    "    axes[0].set_title(f\"Bicubic\\nPSNR: {psnr_bic:.2f} dB | SSIM: {ssim_bic:.4f}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sr_01)\n",
    "    title_col = \"green\" if psnr_sr > psnr_bic else \"black\"\n",
    "    axes[1].set_title(\n",
    "        f\"Attentive ESRGAN\\nPSNR: {psnr_sr:.2f} dB | SSIM: {ssim_sr:.4f}\",\n",
    "        color=title_col, fontweight=\"bold\",\n",
    "    )\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(hr_01)\n",
    "    axes[2].set_title(\"Ground Truth\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Attentive ESRGAN models & helpers defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T05:47:20.978345Z",
     "iopub.status.busy": "2025-12-12T05:47:20.977804Z",
     "iopub.status.idle": "2025-12-12T10:25:36.354653Z",
     "shell.execute_reply": "2025-12-12T10:25:36.353854Z",
     "shell.execute_reply.started": "2025-12-12T05:47:20.978321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attentive ESRGAN] Starting training (RaLSGAN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_462']\n",
      "Received: inputs=Tensor(shape=(16, 128, 128, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attentive ESRGAN] Epoch 1/100 Step 0/50 | D: 1.3509 | G: 0.1321\n",
      "[Attentive ESRGAN] Epoch 1/100 Step 10/50 | D: 1.6118 | G: 0.1139\n",
      "[Attentive ESRGAN] Epoch 1/100 Step 20/50 | D: 2.6380 | G: 0.1706\n",
      "[Attentive ESRGAN] Epoch 1/100 Step 30/50 | D: 0.9081 | G: 0.1625\n",
      "[Attentive ESRGAN] Epoch 1/100 Step 40/50 | D: 1.0236 | G: 0.1425\n",
      "[Attentive ESRGAN] Epoch 1 VAL | PSNR: 21.24 dB | SSIM: 0.5260\n",
      "[Attentive ESRGAN] Epoch 1 done in 174.6s | D: 2.1114 | G: 0.1428\n",
      "[Attentive ESRGAN] Epoch 2/100 Step 0/50 | D: 0.7063 | G: 0.0774\n",
      "[Attentive ESRGAN] Epoch 2/100 Step 10/50 | D: 0.9908 | G: 0.1407\n",
      "[Attentive ESRGAN] Epoch 2/100 Step 20/50 | D: 0.6910 | G: 0.0913\n",
      "[Attentive ESRGAN] Epoch 2/100 Step 30/50 | D: 0.3261 | G: 0.1947\n",
      "[Attentive ESRGAN] Epoch 2/100 Step 40/50 | D: 0.6228 | G: 0.1789\n",
      "[Attentive ESRGAN] Epoch 2 VAL | PSNR: 21.16 dB | SSIM: 0.5388\n",
      "[Attentive ESRGAN] Epoch 2 done in 169.2s | D: 0.5406 | G: 0.1293\n",
      "[Attentive ESRGAN] Epoch 3/100 Step 0/50 | D: 0.8355 | G: 0.0866\n",
      "[Attentive ESRGAN] Epoch 3/100 Step 10/50 | D: 0.8940 | G: 0.0713\n",
      "[Attentive ESRGAN] Epoch 3/100 Step 20/50 | D: 0.2793 | G: 0.1224\n",
      "[Attentive ESRGAN] Epoch 3/100 Step 30/50 | D: 0.3914 | G: 0.1588\n",
      "[Attentive ESRGAN] Epoch 3/100 Step 40/50 | D: 1.1293 | G: 0.1465\n",
      "[Attentive ESRGAN] Epoch 3 VAL | PSNR: 21.23 dB | SSIM: 0.5218\n",
      "[Attentive ESRGAN] Epoch 3 done in 169.3s | D: 0.5266 | G: 0.1282\n",
      "[Attentive ESRGAN] Epoch 4/100 Step 0/50 | D: 0.5412 | G: 0.2044\n",
      "[Attentive ESRGAN] Epoch 4/100 Step 10/50 | D: 0.6632 | G: 0.0770\n",
      "[Attentive ESRGAN] Epoch 4/100 Step 20/50 | D: 0.7440 | G: 0.1070\n",
      "[Attentive ESRGAN] Epoch 4/100 Step 30/50 | D: 0.4399 | G: 0.1988\n",
      "[Attentive ESRGAN] Epoch 4/100 Step 40/50 | D: 0.5847 | G: 0.1379\n",
      "[Attentive ESRGAN] Epoch 4 VAL | PSNR: 20.56 dB | SSIM: 0.4918\n",
      "[Attentive ESRGAN] Epoch 4 done in 168.3s | D: 0.3637 | G: 0.1325\n",
      "[Attentive ESRGAN] Epoch 5/100 Step 0/50 | D: 0.5665 | G: 0.0865\n",
      "[Attentive ESRGAN] Epoch 5/100 Step 10/50 | D: 0.5820 | G: 0.0802\n",
      "[Attentive ESRGAN] Epoch 5/100 Step 20/50 | D: 0.5611 | G: 0.1253\n",
      "[Attentive ESRGAN] Epoch 5/100 Step 30/50 | D: 0.4876 | G: 0.1232\n",
      "[Attentive ESRGAN] Epoch 5/100 Step 40/50 | D: 0.3753 | G: 0.1274\n",
      "[Attentive ESRGAN] Epoch 5 VAL | PSNR: 20.89 dB | SSIM: 0.5145\n",
      "[Attentive ESRGAN] Epoch 5 done in 168.3s | D: 0.4072 | G: 0.1274\n",
      "[Attentive ESRGAN] Epoch 6/100 Step 0/50 | D: 0.8343 | G: 0.1216\n",
      "[Attentive ESRGAN] Epoch 6/100 Step 10/50 | D: 0.2736 | G: 0.0701\n",
      "[Attentive ESRGAN] Epoch 6/100 Step 20/50 | D: 0.2865 | G: 0.1388\n",
      "[Attentive ESRGAN] Epoch 6/100 Step 30/50 | D: 0.6112 | G: 0.1778\n",
      "[Attentive ESRGAN] Epoch 6/100 Step 40/50 | D: 0.1541 | G: 0.1571\n",
      "[Attentive ESRGAN] Epoch 6 VAL | PSNR: 19.72 dB | SSIM: 0.5237\n",
      "[Attentive ESRGAN] Epoch 6 done in 169.1s | D: 0.3473 | G: 0.1258\n",
      "[Attentive ESRGAN] Epoch 7/100 Step 0/50 | D: 0.3827 | G: 0.0930\n",
      "[Attentive ESRGAN] Epoch 7/100 Step 10/50 | D: 0.3111 | G: 0.1103\n",
      "[Attentive ESRGAN] Epoch 7/100 Step 20/50 | D: 0.3926 | G: 0.0907\n",
      "[Attentive ESRGAN] Epoch 7/100 Step 30/50 | D: 0.3766 | G: 0.1855\n",
      "[Attentive ESRGAN] Epoch 7/100 Step 40/50 | D: 0.4611 | G: 0.1196\n",
      "[Attentive ESRGAN] Epoch 7 VAL | PSNR: 21.21 dB | SSIM: 0.5472\n",
      "[Attentive ESRGAN] Epoch 7 done in 167.3s | D: 0.4334 | G: 0.1218\n",
      "[Attentive ESRGAN] Epoch 8/100 Step 0/50 | D: 0.2554 | G: 0.1538\n",
      "[Attentive ESRGAN] Epoch 8/100 Step 10/50 | D: 0.2588 | G: 0.1278\n",
      "[Attentive ESRGAN] Epoch 8/100 Step 20/50 | D: 0.4808 | G: 0.0967\n",
      "[Attentive ESRGAN] Epoch 8/100 Step 30/50 | D: 0.4305 | G: 0.1395\n",
      "[Attentive ESRGAN] Epoch 8/100 Step 40/50 | D: 0.2575 | G: 0.1034\n",
      "[Attentive ESRGAN] Epoch 8 VAL | PSNR: 20.48 dB | SSIM: 0.4996\n",
      "[Attentive ESRGAN] Epoch 8 done in 167.8s | D: 0.3889 | G: 0.1254\n",
      "[Attentive ESRGAN] Epoch 9/100 Step 0/50 | D: 0.8606 | G: 0.0662\n",
      "[Attentive ESRGAN] Epoch 9/100 Step 10/50 | D: 0.2615 | G: 0.0964\n",
      "[Attentive ESRGAN] Epoch 9/100 Step 20/50 | D: 0.3650 | G: 0.0777\n",
      "[Attentive ESRGAN] Epoch 9/100 Step 30/50 | D: 0.2908 | G: 0.1854\n",
      "[Attentive ESRGAN] Epoch 9/100 Step 40/50 | D: 0.1925 | G: 0.1919\n",
      "[Attentive ESRGAN] Epoch 9 VAL | PSNR: 20.48 dB | SSIM: 0.4727\n",
      "[Attentive ESRGAN] Epoch 9 done in 168.1s | D: 0.3531 | G: 0.1238\n",
      "[Attentive ESRGAN] Epoch 10/100 Step 0/50 | D: 0.2379 | G: 0.0887\n",
      "[Attentive ESRGAN] Epoch 10/100 Step 10/50 | D: 0.1898 | G: 0.0908\n",
      "[Attentive ESRGAN] Epoch 10/100 Step 20/50 | D: 0.3598 | G: 0.1120\n",
      "[Attentive ESRGAN] Epoch 10/100 Step 30/50 | D: 0.4556 | G: 0.1749\n",
      "[Attentive ESRGAN] Epoch 10/100 Step 40/50 | D: 0.2769 | G: 0.1275\n",
      "[Attentive ESRGAN] Epoch 10 VAL | PSNR: 22.30 dB | SSIM: 0.5539\n",
      "[Attentive ESRGAN] Epoch 10 done in 167.8s | D: 0.2994 | G: 0.1214\n",
      "[Attentive ESRGAN] Epoch 11/100 Step 0/50 | D: 0.3899 | G: 0.0693\n",
      "[Attentive ESRGAN] Epoch 11/100 Step 10/50 | D: 0.2366 | G: 0.0426\n",
      "[Attentive ESRGAN] Epoch 11/100 Step 20/50 | D: 0.1666 | G: 0.0812\n",
      "[Attentive ESRGAN] Epoch 11/100 Step 30/50 | D: 0.1161 | G: 0.1420\n",
      "[Attentive ESRGAN] Epoch 11/100 Step 40/50 | D: 0.2072 | G: 0.0993\n",
      "[Attentive ESRGAN] Epoch 11 VAL | PSNR: 19.78 dB | SSIM: 0.5298\n",
      "[Attentive ESRGAN] Epoch 11 done in 167.6s | D: 0.1985 | G: 0.1102\n",
      "[Attentive ESRGAN] Epoch 12/100 Step 0/50 | D: 0.1218 | G: 0.0973\n",
      "[Attentive ESRGAN] Epoch 12/100 Step 10/50 | D: 0.1099 | G: 0.0845\n",
      "[Attentive ESRGAN] Epoch 12/100 Step 20/50 | D: 0.2631 | G: 0.1164\n",
      "[Attentive ESRGAN] Epoch 12/100 Step 30/50 | D: 0.1621 | G: 0.1507\n",
      "[Attentive ESRGAN] Epoch 12/100 Step 40/50 | D: 0.1806 | G: 0.1077\n",
      "[Attentive ESRGAN] Epoch 12 VAL | PSNR: 21.01 dB | SSIM: 0.5362\n",
      "[Attentive ESRGAN] Epoch 12 done in 167.1s | D: 0.1685 | G: 0.1139\n",
      "[Attentive ESRGAN] Epoch 13/100 Step 0/50 | D: 0.0940 | G: 0.0877\n",
      "[Attentive ESRGAN] Epoch 13/100 Step 10/50 | D: 0.1065 | G: 0.0986\n",
      "[Attentive ESRGAN] Epoch 13/100 Step 20/50 | D: 0.0887 | G: 0.0773\n",
      "[Attentive ESRGAN] Epoch 13/100 Step 30/50 | D: 0.1394 | G: 0.1719\n",
      "[Attentive ESRGAN] Epoch 13/100 Step 40/50 | D: 0.0812 | G: 0.1085\n",
      "[Attentive ESRGAN] Epoch 13 VAL | PSNR: 20.50 dB | SSIM: 0.5744\n",
      "[Attentive ESRGAN] Epoch 13 done in 166.5s | D: 0.1480 | G: 0.1135\n",
      "[Attentive ESRGAN] Epoch 14/100 Step 0/50 | D: 0.1700 | G: 0.0858\n",
      "[Attentive ESRGAN] Epoch 14/100 Step 10/50 | D: 0.1651 | G: 0.0853\n",
      "[Attentive ESRGAN] Epoch 14/100 Step 20/50 | D: 0.0476 | G: 0.1070\n",
      "[Attentive ESRGAN] Epoch 14/100 Step 30/50 | D: 0.0829 | G: 0.1658\n",
      "[Attentive ESRGAN] Epoch 14/100 Step 40/50 | D: 0.1235 | G: 0.1429\n",
      "[Attentive ESRGAN] Epoch 14 VAL | PSNR: 20.19 dB | SSIM: 0.5445\n",
      "[Attentive ESRGAN] Epoch 14 done in 166.8s | D: 0.0886 | G: 0.1167\n",
      "[Attentive ESRGAN] Epoch 15/100 Step 0/50 | D: 0.0732 | G: 0.0852\n",
      "[Attentive ESRGAN] Epoch 15/100 Step 10/50 | D: 0.0700 | G: 0.0934\n",
      "[Attentive ESRGAN] Epoch 15/100 Step 20/50 | D: 0.0703 | G: 0.1172\n",
      "[Attentive ESRGAN] Epoch 15/100 Step 30/50 | D: 0.0745 | G: 0.1814\n",
      "[Attentive ESRGAN] Epoch 15/100 Step 40/50 | D: 0.0462 | G: 0.1635\n",
      "[Attentive ESRGAN] Epoch 15 VAL | PSNR: 21.65 dB | SSIM: 0.5968\n",
      "[Attentive ESRGAN] Epoch 15 done in 167.3s | D: 0.0776 | G: 0.1217\n",
      "[Attentive ESRGAN] Epoch 16/100 Step 0/50 | D: 0.0578 | G: 0.1265\n",
      "[Attentive ESRGAN] Epoch 16/100 Step 10/50 | D: 0.0379 | G: 0.0847\n",
      "[Attentive ESRGAN] Epoch 16/100 Step 20/50 | D: 0.0352 | G: 0.0892\n",
      "[Attentive ESRGAN] Epoch 16/100 Step 30/50 | D: 0.0282 | G: 0.1127\n",
      "[Attentive ESRGAN] Epoch 16/100 Step 40/50 | D: 0.0205 | G: 0.1244\n",
      "[Attentive ESRGAN] Epoch 16 VAL | PSNR: 20.57 dB | SSIM: 0.5593\n",
      "[Attentive ESRGAN] Epoch 16 done in 165.8s | D: 0.0515 | G: 0.1188\n",
      "[Attentive ESRGAN] Epoch 17/100 Step 0/50 | D: 0.0159 | G: 0.1375\n",
      "[Attentive ESRGAN] Epoch 17/100 Step 10/50 | D: 0.0504 | G: 0.1437\n",
      "[Attentive ESRGAN] Epoch 17/100 Step 20/50 | D: 0.0285 | G: 0.1482\n",
      "[Attentive ESRGAN] Epoch 17/100 Step 30/50 | D: 0.0372 | G: 0.1470\n",
      "[Attentive ESRGAN] Epoch 17/100 Step 40/50 | D: 0.0431 | G: 0.1055\n",
      "[Attentive ESRGAN] Epoch 17 VAL | PSNR: 21.93 dB | SSIM: 0.5703\n",
      "[Attentive ESRGAN] Epoch 17 done in 166.7s | D: 0.0460 | G: 0.1142\n",
      "[Attentive ESRGAN] Epoch 18/100 Step 0/50 | D: 0.0487 | G: 0.0952\n",
      "[Attentive ESRGAN] Epoch 18/100 Step 10/50 | D: 0.0115 | G: 0.0880\n",
      "[Attentive ESRGAN] Epoch 18/100 Step 20/50 | D: 0.0142 | G: 0.0888\n",
      "[Attentive ESRGAN] Epoch 18/100 Step 30/50 | D: 0.0140 | G: 0.1954\n",
      "[Attentive ESRGAN] Epoch 18/100 Step 40/50 | D: 0.0149 | G: 0.0884\n",
      "[Attentive ESRGAN] Epoch 18 VAL | PSNR: 21.79 dB | SSIM: 0.5704\n",
      "[Attentive ESRGAN] Epoch 18 done in 166.2s | D: 0.0261 | G: 0.1167\n",
      "[Attentive ESRGAN] Epoch 19/100 Step 0/50 | D: 0.0506 | G: 0.0954\n",
      "[Attentive ESRGAN] Epoch 19/100 Step 10/50 | D: 0.0200 | G: 0.0597\n",
      "[Attentive ESRGAN] Epoch 19/100 Step 20/50 | D: 0.0314 | G: 0.0825\n",
      "[Attentive ESRGAN] Epoch 19/100 Step 30/50 | D: 0.0074 | G: 0.1726\n",
      "[Attentive ESRGAN] Epoch 19/100 Step 40/50 | D: 0.0310 | G: 0.1367\n",
      "[Attentive ESRGAN] Epoch 19 VAL | PSNR: 21.14 dB | SSIM: 0.5974\n",
      "[Attentive ESRGAN] Epoch 19 done in 166.4s | D: 0.0253 | G: 0.1199\n",
      "[Attentive ESRGAN] Epoch 20/100 Step 0/50 | D: 0.0062 | G: 0.1129\n",
      "[Attentive ESRGAN] Epoch 20/100 Step 10/50 | D: 0.0126 | G: 0.1008\n",
      "[Attentive ESRGAN] Epoch 20/100 Step 20/50 | D: 0.0098 | G: 0.0850\n",
      "[Attentive ESRGAN] Epoch 20/100 Step 30/50 | D: 0.0080 | G: 0.1463\n",
      "[Attentive ESRGAN] Epoch 20/100 Step 40/50 | D: 0.0085 | G: 0.1050\n",
      "[Attentive ESRGAN] Epoch 20 VAL | PSNR: 21.75 dB | SSIM: 0.6134\n",
      "[Attentive ESRGAN] Epoch 20 done in 166.3s | D: 0.0159 | G: 0.1110\n",
      "[Attentive ESRGAN] Epoch 21/100 Step 0/50 | D: 0.0095 | G: 0.0655\n",
      "[Attentive ESRGAN] Epoch 21/100 Step 10/50 | D: 0.0073 | G: 0.1301\n",
      "[Attentive ESRGAN] Epoch 21/100 Step 20/50 | D: 0.0126 | G: 0.0838\n",
      "[Attentive ESRGAN] Epoch 21/100 Step 30/50 | D: 0.0113 | G: 0.1567\n",
      "[Attentive ESRGAN] Epoch 21/100 Step 40/50 | D: 0.0115 | G: 0.1371\n",
      "[Attentive ESRGAN] Epoch 21 VAL | PSNR: 21.02 dB | SSIM: 0.5850\n",
      "[Attentive ESRGAN] Epoch 21 done in 165.9s | D: 0.0177 | G: 0.1125\n",
      "[Attentive ESRGAN] Epoch 22/100 Step 0/50 | D: 0.0080 | G: 0.1132\n",
      "[Attentive ESRGAN] Epoch 22/100 Step 10/50 | D: 0.0183 | G: 0.0777\n",
      "[Attentive ESRGAN] Epoch 22/100 Step 20/50 | D: 0.0089 | G: 0.1138\n",
      "[Attentive ESRGAN] Epoch 22/100 Step 30/50 | D: 0.0107 | G: 0.1644\n",
      "[Attentive ESRGAN] Epoch 22/100 Step 40/50 | D: 0.0298 | G: 0.1453\n",
      "[Attentive ESRGAN] Epoch 22 VAL | PSNR: 21.25 dB | SSIM: 0.5984\n",
      "[Attentive ESRGAN] Epoch 22 done in 165.9s | D: 0.0127 | G: 0.1159\n",
      "[Attentive ESRGAN] Epoch 23/100 Step 0/50 | D: 0.0061 | G: 0.0763\n",
      "[Attentive ESRGAN] Epoch 23/100 Step 10/50 | D: 0.0071 | G: 0.1126\n",
      "[Attentive ESRGAN] Epoch 23/100 Step 20/50 | D: 0.0171 | G: 0.0987\n",
      "[Attentive ESRGAN] Epoch 23/100 Step 30/50 | D: 0.0453 | G: 0.1748\n",
      "[Attentive ESRGAN] Epoch 23/100 Step 40/50 | D: 0.0394 | G: 0.1403\n",
      "[Attentive ESRGAN] Epoch 23 VAL | PSNR: 21.38 dB | SSIM: 0.5957\n",
      "[Attentive ESRGAN] Epoch 23 done in 166.6s | D: 0.0148 | G: 0.1172\n",
      "[Attentive ESRGAN] Epoch 24/100 Step 0/50 | D: 0.0044 | G: 0.1029\n",
      "[Attentive ESRGAN] Epoch 24/100 Step 10/50 | D: 0.0047 | G: 0.1116\n",
      "[Attentive ESRGAN] Epoch 24/100 Step 20/50 | D: 0.0063 | G: 0.1052\n",
      "[Attentive ESRGAN] Epoch 24/100 Step 30/50 | D: 0.0096 | G: 0.0947\n",
      "[Attentive ESRGAN] Epoch 24/100 Step 40/50 | D: 0.0094 | G: 0.1075\n",
      "[Attentive ESRGAN] Epoch 24 VAL | PSNR: 21.71 dB | SSIM: 0.6013\n",
      "[Attentive ESRGAN] Epoch 24 done in 166.0s | D: 0.0127 | G: 0.1120\n",
      "[Attentive ESRGAN] Epoch 25/100 Step 0/50 | D: 0.0039 | G: 0.0690\n",
      "[Attentive ESRGAN] Epoch 25/100 Step 10/50 | D: 0.0155 | G: 0.1200\n",
      "[Attentive ESRGAN] Epoch 25/100 Step 20/50 | D: 0.0024 | G: 0.1214\n",
      "[Attentive ESRGAN] Epoch 25/100 Step 30/50 | D: 0.0052 | G: 0.1695\n",
      "[Attentive ESRGAN] Epoch 25/100 Step 40/50 | D: 0.0044 | G: 0.1385\n",
      "[Attentive ESRGAN] Epoch 25 VAL | PSNR: 22.81 dB | SSIM: 0.6412\n",
      "[Attentive ESRGAN] Epoch 25 done in 165.5s | D: 0.0107 | G: 0.1143\n",
      "[Attentive ESRGAN] Epoch 26/100 Step 0/50 | D: 0.0149 | G: 0.0732\n",
      "[Attentive ESRGAN] Epoch 26/100 Step 10/50 | D: 0.0073 | G: 0.0829\n",
      "[Attentive ESRGAN] Epoch 26/100 Step 20/50 | D: 0.0210 | G: 0.1179\n",
      "[Attentive ESRGAN] Epoch 26/100 Step 30/50 | D: 0.0316 | G: 0.1158\n",
      "[Attentive ESRGAN] Epoch 26/100 Step 40/50 | D: 0.0038 | G: 0.1265\n",
      "[Attentive ESRGAN] Epoch 26 VAL | PSNR: 21.38 dB | SSIM: 0.6179\n",
      "[Attentive ESRGAN] Epoch 26 done in 166.7s | D: 0.0104 | G: 0.1123\n",
      "[Attentive ESRGAN] Epoch 27/100 Step 0/50 | D: 0.0046 | G: 0.1399\n",
      "[Attentive ESRGAN] Epoch 27/100 Step 10/50 | D: 0.0103 | G: 0.0583\n",
      "[Attentive ESRGAN] Epoch 27/100 Step 20/50 | D: 0.0025 | G: 0.0785\n",
      "[Attentive ESRGAN] Epoch 27/100 Step 30/50 | D: 0.0037 | G: 0.1361\n",
      "[Attentive ESRGAN] Epoch 27/100 Step 40/50 | D: 0.0043 | G: 0.1194\n",
      "[Attentive ESRGAN] Epoch 27 VAL | PSNR: 21.68 dB | SSIM: 0.6026\n",
      "[Attentive ESRGAN] Epoch 27 done in 166.4s | D: 0.0067 | G: 0.1068\n",
      "[Attentive ESRGAN] Epoch 28/100 Step 0/50 | D: 0.0039 | G: 0.1056\n",
      "[Attentive ESRGAN] Epoch 28/100 Step 10/50 | D: 0.0177 | G: 0.1031\n",
      "[Attentive ESRGAN] Epoch 28/100 Step 20/50 | D: 0.0162 | G: 0.1219\n",
      "[Attentive ESRGAN] Epoch 28/100 Step 30/50 | D: 0.0238 | G: 0.1235\n",
      "[Attentive ESRGAN] Epoch 28/100 Step 40/50 | D: 0.0042 | G: 0.1368\n",
      "[Attentive ESRGAN] Epoch 28 VAL | PSNR: 21.65 dB | SSIM: 0.5925\n",
      "[Attentive ESRGAN] Epoch 28 done in 167.0s | D: 0.0121 | G: 0.1156\n",
      "[Attentive ESRGAN] Epoch 29/100 Step 0/50 | D: 0.0395 | G: 0.0925\n",
      "[Attentive ESRGAN] Epoch 29/100 Step 10/50 | D: 0.0263 | G: 0.0728\n",
      "[Attentive ESRGAN] Epoch 29/100 Step 20/50 | D: 0.0045 | G: 0.0950\n",
      "[Attentive ESRGAN] Epoch 29/100 Step 30/50 | D: 0.0119 | G: 0.1598\n",
      "[Attentive ESRGAN] Epoch 29/100 Step 40/50 | D: 0.0263 | G: 0.0937\n",
      "[Attentive ESRGAN] Epoch 29 VAL | PSNR: 21.65 dB | SSIM: 0.5931\n",
      "[Attentive ESRGAN] Epoch 29 done in 166.9s | D: 0.0113 | G: 0.1027\n",
      "[Attentive ESRGAN] Epoch 30/100 Step 0/50 | D: 0.0067 | G: 0.0977\n",
      "[Attentive ESRGAN] Epoch 30/100 Step 10/50 | D: 0.0138 | G: 0.0708\n",
      "[Attentive ESRGAN] Epoch 30/100 Step 20/50 | D: 0.0028 | G: 0.0796\n",
      "[Attentive ESRGAN] Epoch 30/100 Step 30/50 | D: 0.0031 | G: 0.1971\n",
      "[Attentive ESRGAN] Epoch 30/100 Step 40/50 | D: 0.0027 | G: 0.1050\n",
      "[Attentive ESRGAN] Epoch 30 VAL | PSNR: 22.21 dB | SSIM: 0.6139\n",
      "[Attentive ESRGAN] Epoch 30 done in 166.4s | D: 0.0078 | G: 0.1136\n",
      "[Attentive ESRGAN] Epoch 31/100 Step 0/50 | D: 0.0029 | G: 0.0560\n",
      "[Attentive ESRGAN] Epoch 31/100 Step 10/50 | D: 0.0139 | G: 0.1030\n",
      "[Attentive ESRGAN] Epoch 31/100 Step 20/50 | D: 0.0142 | G: 0.1064\n",
      "[Attentive ESRGAN] Epoch 31/100 Step 30/50 | D: 0.0041 | G: 0.1220\n",
      "[Attentive ESRGAN] Epoch 31/100 Step 40/50 | D: 0.0212 | G: 0.1399\n",
      "[Attentive ESRGAN] Epoch 31 VAL | PSNR: 21.39 dB | SSIM: 0.5859\n",
      "[Attentive ESRGAN] Epoch 31 done in 165.4s | D: 0.0086 | G: 0.1063\n",
      "[Attentive ESRGAN] Epoch 32/100 Step 0/50 | D: 0.0785 | G: 0.0649\n",
      "[Attentive ESRGAN] Epoch 32/100 Step 10/50 | D: 0.0282 | G: 0.0953\n",
      "[Attentive ESRGAN] Epoch 32/100 Step 20/50 | D: 0.0043 | G: 0.1015\n",
      "[Attentive ESRGAN] Epoch 32/100 Step 30/50 | D: 0.0151 | G: 0.1785\n",
      "[Attentive ESRGAN] Epoch 32/100 Step 40/50 | D: 0.0053 | G: 0.1436\n",
      "[Attentive ESRGAN] Epoch 32 VAL | PSNR: 23.01 dB | SSIM: 0.5922\n",
      "[Attentive ESRGAN] Epoch 32 done in 165.9s | D: 0.0136 | G: 0.1112\n",
      "[Attentive ESRGAN] Epoch 33/100 Step 0/50 | D: 0.0027 | G: 0.1484\n",
      "[Attentive ESRGAN] Epoch 33/100 Step 10/50 | D: 0.0147 | G: 0.0913\n",
      "[Attentive ESRGAN] Epoch 33/100 Step 20/50 | D: 0.0031 | G: 0.1390\n",
      "[Attentive ESRGAN] Epoch 33/100 Step 30/50 | D: 0.0039 | G: 0.1029\n",
      "[Attentive ESRGAN] Epoch 33/100 Step 40/50 | D: 0.0143 | G: 0.0765\n",
      "[Attentive ESRGAN] Epoch 33 VAL | PSNR: 22.13 dB | SSIM: 0.5893\n",
      "[Attentive ESRGAN] Epoch 33 done in 168.5s | D: 0.0127 | G: 0.1102\n",
      "[Attentive ESRGAN] Epoch 34/100 Step 0/50 | D: 0.0105 | G: 0.1062\n",
      "[Attentive ESRGAN] Epoch 34/100 Step 10/50 | D: 0.0154 | G: 0.1157\n",
      "[Attentive ESRGAN] Epoch 34/100 Step 20/50 | D: 0.0035 | G: 0.1028\n",
      "[Attentive ESRGAN] Epoch 34/100 Step 30/50 | D: 0.0030 | G: 0.0676\n",
      "[Attentive ESRGAN] Epoch 34/100 Step 40/50 | D: 0.0113 | G: 0.1105\n",
      "[Attentive ESRGAN] Epoch 34 VAL | PSNR: 22.61 dB | SSIM: 0.5863\n",
      "[Attentive ESRGAN] Epoch 34 done in 166.8s | D: 0.0082 | G: 0.1028\n",
      "[Attentive ESRGAN] Epoch 35/100 Step 0/50 | D: 0.0099 | G: 0.0966\n",
      "[Attentive ESRGAN] Epoch 35/100 Step 10/50 | D: 0.0052 | G: 0.0936\n",
      "[Attentive ESRGAN] Epoch 35/100 Step 20/50 | D: 0.0173 | G: 0.1301\n",
      "[Attentive ESRGAN] Epoch 35/100 Step 30/50 | D: 0.0035 | G: 0.1364\n",
      "[Attentive ESRGAN] Epoch 35/100 Step 40/50 | D: 0.0219 | G: 0.1431\n",
      "[Attentive ESRGAN] Epoch 35 VAL | PSNR: 21.88 dB | SSIM: 0.6156\n",
      "[Attentive ESRGAN] Epoch 35 done in 165.4s | D: 0.0119 | G: 0.1145\n",
      "[Attentive ESRGAN] Epoch 36/100 Step 0/50 | D: 0.0094 | G: 0.0949\n",
      "[Attentive ESRGAN] Epoch 36/100 Step 10/50 | D: 0.0343 | G: 0.1148\n",
      "[Attentive ESRGAN] Epoch 36/100 Step 20/50 | D: 0.0095 | G: 0.0660\n",
      "[Attentive ESRGAN] Epoch 36/100 Step 30/50 | D: 0.0262 | G: 0.1251\n",
      "[Attentive ESRGAN] Epoch 36/100 Step 40/50 | D: 0.0049 | G: 0.1393\n",
      "[Attentive ESRGAN] Epoch 36 VAL | PSNR: 20.92 dB | SSIM: 0.5819\n",
      "[Attentive ESRGAN] Epoch 36 done in 166.9s | D: 0.0122 | G: 0.1116\n",
      "[Attentive ESRGAN] Epoch 37/100 Step 0/50 | D: 0.0027 | G: 0.1010\n",
      "[Attentive ESRGAN] Epoch 37/100 Step 10/50 | D: 0.0018 | G: 0.0708\n",
      "[Attentive ESRGAN] Epoch 37/100 Step 20/50 | D: 0.0033 | G: 0.0719\n",
      "[Attentive ESRGAN] Epoch 37/100 Step 30/50 | D: 0.0230 | G: 0.1455\n",
      "[Attentive ESRGAN] Epoch 37/100 Step 40/50 | D: 0.0036 | G: 0.1076\n",
      "[Attentive ESRGAN] Epoch 37 VAL | PSNR: 22.04 dB | SSIM: 0.6034\n",
      "[Attentive ESRGAN] Epoch 37 done in 166.4s | D: 0.0088 | G: 0.1033\n",
      "[Attentive ESRGAN] Epoch 38/100 Step 0/50 | D: 0.0187 | G: 0.1300\n",
      "[Attentive ESRGAN] Epoch 38/100 Step 10/50 | D: 0.0048 | G: 0.1242\n",
      "[Attentive ESRGAN] Epoch 38/100 Step 20/50 | D: 0.0153 | G: 0.1352\n",
      "[Attentive ESRGAN] Epoch 38/100 Step 30/50 | D: 0.0042 | G: 0.1384\n",
      "[Attentive ESRGAN] Epoch 38/100 Step 40/50 | D: 0.0020 | G: 0.1172\n",
      "[Attentive ESRGAN] Epoch 38 VAL | PSNR: 22.29 dB | SSIM: 0.5940\n",
      "[Attentive ESRGAN] Epoch 38 done in 165.8s | D: 0.0115 | G: 0.1136\n",
      "[Attentive ESRGAN] Epoch 39/100 Step 0/50 | D: 0.0037 | G: 0.0894\n",
      "[Attentive ESRGAN] Epoch 39/100 Step 10/50 | D: 0.0036 | G: 0.1068\n",
      "[Attentive ESRGAN] Epoch 39/100 Step 20/50 | D: 0.0243 | G: 0.0987\n",
      "[Attentive ESRGAN] Epoch 39/100 Step 30/50 | D: 0.0032 | G: 0.1536\n",
      "[Attentive ESRGAN] Epoch 39/100 Step 40/50 | D: 0.0125 | G: 0.1340\n",
      "[Attentive ESRGAN] Epoch 39 VAL | PSNR: 22.60 dB | SSIM: 0.6078\n",
      "[Attentive ESRGAN] Epoch 39 done in 167.5s | D: 0.0080 | G: 0.1091\n",
      "[Attentive ESRGAN] Epoch 40/100 Step 0/50 | D: 0.0181 | G: 0.0897\n",
      "[Attentive ESRGAN] Epoch 40/100 Step 10/50 | D: 0.0132 | G: 0.0676\n",
      "[Attentive ESRGAN] Epoch 40/100 Step 20/50 | D: 0.0057 | G: 0.0672\n",
      "[Attentive ESRGAN] Epoch 40/100 Step 30/50 | D: 0.0020 | G: 0.1927\n",
      "[Attentive ESRGAN] Epoch 40/100 Step 40/50 | D: 0.0010 | G: 0.0833\n",
      "[Attentive ESRGAN] Epoch 40 VAL | PSNR: 21.77 dB | SSIM: 0.5770\n",
      "[Attentive ESRGAN] Epoch 40 done in 165.9s | D: 0.0070 | G: 0.1069\n",
      "[Attentive ESRGAN] Epoch 41/100 Step 0/50 | D: 0.0450 | G: 0.1514\n",
      "[Attentive ESRGAN] Epoch 41/100 Step 10/50 | D: 0.0041 | G: 0.0910\n",
      "[Attentive ESRGAN] Epoch 41/100 Step 20/50 | D: 0.0026 | G: 0.1006\n",
      "[Attentive ESRGAN] Epoch 41/100 Step 30/50 | D: 0.0061 | G: 0.1363\n",
      "[Attentive ESRGAN] Epoch 41/100 Step 40/50 | D: 0.0043 | G: 0.0858\n",
      "[Attentive ESRGAN] Epoch 41 VAL | PSNR: 21.69 dB | SSIM: 0.5838\n",
      "[Attentive ESRGAN] Epoch 41 done in 166.7s | D: 0.0076 | G: 0.1116\n",
      "[Attentive ESRGAN] Epoch 42/100 Step 0/50 | D: 0.0027 | G: 0.0726\n",
      "[Attentive ESRGAN] Epoch 42/100 Step 10/50 | D: 0.0016 | G: 0.0684\n",
      "[Attentive ESRGAN] Epoch 42/100 Step 20/50 | D: 0.0016 | G: 0.1023\n",
      "[Attentive ESRGAN] Epoch 42/100 Step 30/50 | D: 0.0036 | G: 0.1838\n",
      "[Attentive ESRGAN] Epoch 42/100 Step 40/50 | D: 0.0106 | G: 0.0970\n",
      "[Attentive ESRGAN] Epoch 42 VAL | PSNR: 22.23 dB | SSIM: 0.5583\n",
      "[Attentive ESRGAN] Epoch 42 done in 166.6s | D: 0.0057 | G: 0.1088\n",
      "[Attentive ESRGAN] Epoch 43/100 Step 0/50 | D: 0.0134 | G: 0.0730\n",
      "[Attentive ESRGAN] Epoch 43/100 Step 10/50 | D: 0.0130 | G: 0.1072\n",
      "[Attentive ESRGAN] Epoch 43/100 Step 20/50 | D: 0.0036 | G: 0.0996\n",
      "[Attentive ESRGAN] Epoch 43/100 Step 30/50 | D: 0.0027 | G: 0.1290\n",
      "[Attentive ESRGAN] Epoch 43/100 Step 40/50 | D: 0.0020 | G: 0.1298\n",
      "[Attentive ESRGAN] Epoch 43 VAL | PSNR: 21.35 dB | SSIM: 0.5875\n",
      "[Attentive ESRGAN] Epoch 43 done in 167.2s | D: 0.0084 | G: 0.1092\n",
      "[Attentive ESRGAN] Epoch 44/100 Step 0/50 | D: 0.0025 | G: 0.0875\n",
      "[Attentive ESRGAN] Epoch 44/100 Step 10/50 | D: 0.0062 | G: 0.0804\n",
      "[Attentive ESRGAN] Epoch 44/100 Step 20/50 | D: 0.0151 | G: 0.0934\n",
      "[Attentive ESRGAN] Epoch 44/100 Step 30/50 | D: 0.0252 | G: 0.0721\n",
      "[Attentive ESRGAN] Epoch 44/100 Step 40/50 | D: 0.0149 | G: 0.1137\n",
      "[Attentive ESRGAN] Epoch 44 VAL | PSNR: 21.10 dB | SSIM: 0.5628\n",
      "[Attentive ESRGAN] Epoch 44 done in 166.8s | D: 0.0083 | G: 0.1033\n",
      "[Attentive ESRGAN] Epoch 45/100 Step 0/50 | D: 0.0126 | G: 0.1199\n",
      "[Attentive ESRGAN] Epoch 45/100 Step 10/50 | D: 0.0018 | G: 0.1174\n",
      "[Attentive ESRGAN] Epoch 45/100 Step 20/50 | D: 0.0275 | G: 0.0801\n",
      "[Attentive ESRGAN] Epoch 45/100 Step 30/50 | D: 0.0017 | G: 0.1280\n",
      "[Attentive ESRGAN] Epoch 45/100 Step 40/50 | D: 0.0083 | G: 0.0973\n",
      "[Attentive ESRGAN] Epoch 45 VAL | PSNR: 21.62 dB | SSIM: 0.5775\n",
      "[Attentive ESRGAN] Epoch 45 done in 165.7s | D: 0.0065 | G: 0.1070\n",
      "[Attentive ESRGAN] Epoch 46/100 Step 0/50 | D: 0.0059 | G: 0.1501\n",
      "[Attentive ESRGAN] Epoch 46/100 Step 10/50 | D: 0.0090 | G: 0.1355\n",
      "[Attentive ESRGAN] Epoch 46/100 Step 20/50 | D: 0.0050 | G: 0.0672\n",
      "[Attentive ESRGAN] Epoch 46/100 Step 30/50 | D: 0.0026 | G: 0.1530\n",
      "[Attentive ESRGAN] Epoch 46/100 Step 40/50 | D: 0.0032 | G: 0.0918\n",
      "[Attentive ESRGAN] Epoch 46 VAL | PSNR: 22.59 dB | SSIM: 0.6160\n",
      "[Attentive ESRGAN] Epoch 46 done in 167.6s | D: 0.0038 | G: 0.1135\n",
      "[Attentive ESRGAN] Epoch 47/100 Step 0/50 | D: 0.0007 | G: 0.0478\n",
      "[Attentive ESRGAN] Epoch 47/100 Step 10/50 | D: 0.0017 | G: 0.0665\n",
      "[Attentive ESRGAN] Epoch 47/100 Step 20/50 | D: 0.0067 | G: 0.0860\n",
      "[Attentive ESRGAN] Epoch 47/100 Step 30/50 | D: 0.0064 | G: 0.1194\n",
      "[Attentive ESRGAN] Epoch 47/100 Step 40/50 | D: 0.0015 | G: 0.0901\n",
      "[Attentive ESRGAN] Epoch 47 VAL | PSNR: 21.50 dB | SSIM: 0.5744\n",
      "[Attentive ESRGAN] Epoch 47 done in 165.7s | D: 0.0054 | G: 0.1066\n",
      "[Attentive ESRGAN] Epoch 48/100 Step 0/50 | D: 0.0013 | G: 0.1144\n",
      "[Attentive ESRGAN] Epoch 48/100 Step 10/50 | D: 0.0217 | G: 0.0931\n",
      "[Attentive ESRGAN] Epoch 48/100 Step 20/50 | D: 0.0846 | G: 0.1036\n",
      "[Attentive ESRGAN] Epoch 48/100 Step 30/50 | D: 0.0062 | G: 0.1558\n",
      "[Attentive ESRGAN] Epoch 48/100 Step 40/50 | D: 0.0112 | G: 0.0763\n",
      "[Attentive ESRGAN] Epoch 48 VAL | PSNR: 22.33 dB | SSIM: 0.5754\n",
      "[Attentive ESRGAN] Epoch 48 done in 165.3s | D: 0.0136 | G: 0.1088\n",
      "[Attentive ESRGAN] Epoch 49/100 Step 0/50 | D: 0.0038 | G: 0.0673\n",
      "[Attentive ESRGAN] Epoch 49/100 Step 10/50 | D: 0.0066 | G: 0.0748\n",
      "[Attentive ESRGAN] Epoch 49/100 Step 20/50 | D: 0.0012 | G: 0.0819\n",
      "[Attentive ESRGAN] Epoch 49/100 Step 30/50 | D: 0.0146 | G: 0.1541\n",
      "[Attentive ESRGAN] Epoch 49/100 Step 40/50 | D: 0.0061 | G: 0.1224\n",
      "[Attentive ESRGAN] Epoch 49 VAL | PSNR: 21.52 dB | SSIM: 0.5877\n",
      "[Attentive ESRGAN] Epoch 49 done in 167.0s | D: 0.0081 | G: 0.1046\n",
      "[Attentive ESRGAN] Epoch 50/100 Step 0/50 | D: 0.0095 | G: 0.0394\n",
      "[Attentive ESRGAN] Epoch 50/100 Step 10/50 | D: 0.0020 | G: 0.0764\n",
      "[Attentive ESRGAN] Epoch 50/100 Step 20/50 | D: 0.0028 | G: 0.0829\n",
      "[Attentive ESRGAN] Epoch 50/100 Step 30/50 | D: 0.0062 | G: 0.2303\n",
      "[Attentive ESRGAN] Epoch 50/100 Step 40/50 | D: 0.0021 | G: 0.0769\n",
      "[Attentive ESRGAN] Epoch 50 VAL | PSNR: 22.16 dB | SSIM: 0.5989\n",
      "[Attentive ESRGAN] Epoch 50 done in 165.1s | D: 0.0065 | G: 0.1044\n",
      "[Attentive ESRGAN] Epoch 51/100 Step 0/50 | D: 0.0019 | G: 0.0564\n",
      "[Attentive ESRGAN] Epoch 51/100 Step 10/50 | D: 0.0015 | G: 0.0906\n",
      "[Attentive ESRGAN] Epoch 51/100 Step 20/50 | D: 0.0258 | G: 0.1084\n",
      "[Attentive ESRGAN] Epoch 51/100 Step 30/50 | D: 0.0034 | G: 0.1253\n",
      "[Attentive ESRGAN] Epoch 51/100 Step 40/50 | D: 0.0057 | G: 0.1264\n",
      "[Attentive ESRGAN] Epoch 51 VAL | PSNR: 21.75 dB | SSIM: 0.5935\n",
      "[Attentive ESRGAN] Epoch 51 done in 170.6s | D: 0.0074 | G: 0.1070\n",
      "[Attentive ESRGAN] Epoch 52/100 Step 0/50 | D: 0.0015 | G: 0.0785\n",
      "[Attentive ESRGAN] Epoch 52/100 Step 10/50 | D: 0.0021 | G: 0.0719\n",
      "[Attentive ESRGAN] Epoch 52/100 Step 20/50 | D: 0.0010 | G: 0.0681\n",
      "[Attentive ESRGAN] Epoch 52/100 Step 30/50 | D: 0.0035 | G: 0.1187\n",
      "[Attentive ESRGAN] Epoch 52/100 Step 40/50 | D: 0.0044 | G: 0.1309\n",
      "[Attentive ESRGAN] Epoch 52 VAL | PSNR: 22.02 dB | SSIM: 0.6007\n",
      "[Attentive ESRGAN] Epoch 52 done in 168.2s | D: 0.0051 | G: 0.1077\n",
      "[Attentive ESRGAN] Epoch 53/100 Step 0/50 | D: 0.0015 | G: 0.0807\n",
      "[Attentive ESRGAN] Epoch 53/100 Step 10/50 | D: 0.0023 | G: 0.0801\n",
      "[Attentive ESRGAN] Epoch 53/100 Step 20/50 | D: 0.0026 | G: 0.0959\n",
      "[Attentive ESRGAN] Epoch 53/100 Step 30/50 | D: 0.0054 | G: 0.1723\n",
      "[Attentive ESRGAN] Epoch 53/100 Step 40/50 | D: 0.0011 | G: 0.0936\n",
      "[Attentive ESRGAN] Epoch 53 VAL | PSNR: 23.50 dB | SSIM: 0.6322\n",
      "[Attentive ESRGAN] Epoch 53 done in 167.1s | D: 0.0036 | G: 0.1046\n",
      "[Attentive ESRGAN] Epoch 54/100 Step 0/50 | D: 0.0043 | G: 0.1482\n",
      "[Attentive ESRGAN] Epoch 54/100 Step 10/50 | D: 0.0043 | G: 0.0926\n",
      "[Attentive ESRGAN] Epoch 54/100 Step 20/50 | D: 0.0041 | G: 0.0778\n",
      "[Attentive ESRGAN] Epoch 54/100 Step 30/50 | D: 0.0029 | G: 0.0991\n",
      "[Attentive ESRGAN] Epoch 54/100 Step 40/50 | D: 0.0051 | G: 0.1125\n",
      "[Attentive ESRGAN] Epoch 54 VAL | PSNR: 23.84 dB | SSIM: 0.6370\n",
      "[Attentive ESRGAN] Epoch 54 done in 167.3s | D: 0.0058 | G: 0.1082\n",
      "[Attentive ESRGAN] Epoch 55/100 Step 0/50 | D: 0.0029 | G: 0.1047\n",
      "[Attentive ESRGAN] Epoch 55/100 Step 10/50 | D: 0.0170 | G: 0.0872\n",
      "[Attentive ESRGAN] Epoch 55/100 Step 20/50 | D: 0.0016 | G: 0.0888\n",
      "[Attentive ESRGAN] Epoch 55/100 Step 30/50 | D: 0.0017 | G: 0.1253\n",
      "[Attentive ESRGAN] Epoch 55/100 Step 40/50 | D: 0.0025 | G: 0.1400\n",
      "[Attentive ESRGAN] Epoch 55 VAL | PSNR: 22.51 dB | SSIM: 0.6012\n",
      "[Attentive ESRGAN] Epoch 55 done in 166.9s | D: 0.0067 | G: 0.1083\n",
      "[Attentive ESRGAN] Epoch 56/100 Step 0/50 | D: 0.0006 | G: 0.1101\n",
      "[Attentive ESRGAN] Epoch 56/100 Step 10/50 | D: 0.0015 | G: 0.1051\n",
      "[Attentive ESRGAN] Epoch 56/100 Step 20/50 | D: 0.0019 | G: 0.0931\n",
      "[Attentive ESRGAN] Epoch 56/100 Step 30/50 | D: 0.0025 | G: 0.1229\n",
      "[Attentive ESRGAN] Epoch 56/100 Step 40/50 | D: 0.0040 | G: 0.1048\n",
      "[Attentive ESRGAN] Epoch 56 VAL | PSNR: 22.88 dB | SSIM: 0.6270\n",
      "[Attentive ESRGAN] Epoch 56 done in 166.8s | D: 0.0036 | G: 0.1055\n",
      "[Attentive ESRGAN] Epoch 57/100 Step 0/50 | D: 0.0011 | G: 0.0597\n",
      "[Attentive ESRGAN] Epoch 57/100 Step 10/50 | D: 0.0044 | G: 0.0927\n",
      "[Attentive ESRGAN] Epoch 57/100 Step 20/50 | D: 0.0014 | G: 0.1009\n",
      "[Attentive ESRGAN] Epoch 57/100 Step 30/50 | D: 0.0213 | G: 0.1294\n",
      "[Attentive ESRGAN] Epoch 57/100 Step 40/50 | D: 0.0063 | G: 0.1406\n",
      "[Attentive ESRGAN] Epoch 57 VAL | PSNR: 23.21 dB | SSIM: 0.6185\n",
      "[Attentive ESRGAN] Epoch 57 done in 166.8s | D: 0.0062 | G: 0.1035\n",
      "[Attentive ESRGAN] Epoch 58/100 Step 0/50 | D: 0.0006 | G: 0.0611\n",
      "[Attentive ESRGAN] Epoch 58/100 Step 10/50 | D: 0.0010 | G: 0.1000\n",
      "[Attentive ESRGAN] Epoch 58/100 Step 20/50 | D: 0.0018 | G: 0.0780\n",
      "[Attentive ESRGAN] Epoch 58/100 Step 30/50 | D: 0.0008 | G: 0.0870\n",
      "[Attentive ESRGAN] Epoch 58/100 Step 40/50 | D: 0.0253 | G: 0.1009\n",
      "[Attentive ESRGAN] Epoch 58 VAL | PSNR: 23.39 dB | SSIM: 0.6473\n",
      "[Attentive ESRGAN] Epoch 58 done in 167.9s | D: 0.0053 | G: 0.1049\n",
      "[Attentive ESRGAN] Epoch 59/100 Step 0/50 | D: 0.0023 | G: 0.0928\n",
      "[Attentive ESRGAN] Epoch 59/100 Step 10/50 | D: 0.0123 | G: 0.1316\n",
      "[Attentive ESRGAN] Epoch 59/100 Step 20/50 | D: 0.0057 | G: 0.0888\n",
      "[Attentive ESRGAN] Epoch 59/100 Step 30/50 | D: 0.0042 | G: 0.1696\n",
      "[Attentive ESRGAN] Epoch 59/100 Step 40/50 | D: 0.0193 | G: 0.1102\n",
      "[Attentive ESRGAN] Epoch 59 VAL | PSNR: 23.56 dB | SSIM: 0.6195\n",
      "[Attentive ESRGAN] Epoch 59 done in 168.6s | D: 0.0079 | G: 0.1037\n",
      "[Attentive ESRGAN] Epoch 60/100 Step 0/50 | D: 0.0415 | G: 0.0491\n",
      "[Attentive ESRGAN] Epoch 60/100 Step 10/50 | D: 0.0142 | G: 0.1236\n",
      "[Attentive ESRGAN] Epoch 60/100 Step 20/50 | D: 0.0402 | G: 0.1397\n",
      "[Attentive ESRGAN] Epoch 60/100 Step 30/50 | D: 0.0013 | G: 0.1042\n",
      "[Attentive ESRGAN] Epoch 60/100 Step 40/50 | D: 0.0067 | G: 0.0685\n",
      "[Attentive ESRGAN] Epoch 60 VAL | PSNR: 23.08 dB | SSIM: 0.6335\n",
      "[Attentive ESRGAN] Epoch 60 done in 167.9s | D: 0.0096 | G: 0.1040\n",
      "[Attentive ESRGAN] Epoch 61/100 Step 0/50 | D: 0.0018 | G: 0.0827\n",
      "[Attentive ESRGAN] Epoch 61/100 Step 10/50 | D: 0.0042 | G: 0.0933\n",
      "[Attentive ESRGAN] Epoch 61/100 Step 20/50 | D: 0.0008 | G: 0.0723\n",
      "[Attentive ESRGAN] Epoch 61/100 Step 30/50 | D: 0.0014 | G: 0.1052\n",
      "[Attentive ESRGAN] Epoch 61/100 Step 40/50 | D: 0.0103 | G: 0.1099\n",
      "[Attentive ESRGAN] Epoch 61 VAL | PSNR: 21.83 dB | SSIM: 0.6066\n",
      "[Attentive ESRGAN] Epoch 61 done in 168.4s | D: 0.0045 | G: 0.1069\n",
      "[Attentive ESRGAN] Epoch 62/100 Step 0/50 | D: 0.0086 | G: 0.0897\n",
      "[Attentive ESRGAN] Epoch 62/100 Step 10/50 | D: 0.0079 | G: 0.0834\n",
      "[Attentive ESRGAN] Epoch 62/100 Step 20/50 | D: 0.0047 | G: 0.0958\n",
      "[Attentive ESRGAN] Epoch 62/100 Step 30/50 | D: 0.0158 | G: 0.1081\n",
      "[Attentive ESRGAN] Epoch 62/100 Step 40/50 | D: 0.0033 | G: 0.1007\n",
      "[Attentive ESRGAN] Epoch 62 VAL | PSNR: 22.61 dB | SSIM: 0.6165\n",
      "[Attentive ESRGAN] Epoch 62 done in 167.3s | D: 0.0054 | G: 0.1007\n",
      "[Attentive ESRGAN] Epoch 63/100 Step 0/50 | D: 0.0141 | G: 0.0926\n",
      "[Attentive ESRGAN] Epoch 63/100 Step 10/50 | D: 0.0006 | G: 0.0669\n",
      "[Attentive ESRGAN] Epoch 63/100 Step 20/50 | D: 0.0059 | G: 0.1080\n",
      "[Attentive ESRGAN] Epoch 63/100 Step 30/50 | D: 0.0042 | G: 0.0901\n",
      "[Attentive ESRGAN] Epoch 63/100 Step 40/50 | D: 0.0009 | G: 0.1124\n",
      "[Attentive ESRGAN] Epoch 63 VAL | PSNR: 21.57 dB | SSIM: 0.5795\n",
      "[Attentive ESRGAN] Epoch 63 done in 167.0s | D: 0.0037 | G: 0.1074\n",
      "[Attentive ESRGAN] Epoch 64/100 Step 0/50 | D: 0.0026 | G: 0.0820\n",
      "[Attentive ESRGAN] Epoch 64/100 Step 10/50 | D: 0.0008 | G: 0.0880\n",
      "[Attentive ESRGAN] Epoch 64/100 Step 20/50 | D: 0.0032 | G: 0.0850\n",
      "[Attentive ESRGAN] Epoch 64/100 Step 30/50 | D: 0.0060 | G: 0.1290\n",
      "[Attentive ESRGAN] Epoch 64/100 Step 40/50 | D: 0.0005 | G: 0.1158\n",
      "[Attentive ESRGAN] Epoch 64 VAL | PSNR: 22.35 dB | SSIM: 0.5995\n",
      "[Attentive ESRGAN] Epoch 64 done in 166.7s | D: 0.0033 | G: 0.1133\n",
      "[Attentive ESRGAN] Epoch 65/100 Step 0/50 | D: 0.0045 | G: 0.0932\n",
      "[Attentive ESRGAN] Epoch 65/100 Step 10/50 | D: 0.0015 | G: 0.1025\n",
      "[Attentive ESRGAN] Epoch 65/100 Step 20/50 | D: 0.0043 | G: 0.1315\n",
      "[Attentive ESRGAN] Epoch 65/100 Step 30/50 | D: 0.0172 | G: 0.1382\n",
      "[Attentive ESRGAN] Epoch 65/100 Step 40/50 | D: 0.0103 | G: 0.0906\n",
      "[Attentive ESRGAN] Epoch 65 VAL | PSNR: 22.04 dB | SSIM: 0.5956\n",
      "[Attentive ESRGAN] Epoch 65 done in 167.2s | D: 0.0061 | G: 0.1050\n",
      "[Attentive ESRGAN] Epoch 66/100 Step 0/50 | D: 0.0016 | G: 0.0661\n",
      "[Attentive ESRGAN] Epoch 66/100 Step 10/50 | D: 0.0018 | G: 0.0578\n",
      "[Attentive ESRGAN] Epoch 66/100 Step 20/50 | D: 0.0042 | G: 0.1098\n",
      "[Attentive ESRGAN] Epoch 66/100 Step 30/50 | D: 0.0157 | G: 0.1105\n",
      "[Attentive ESRGAN] Epoch 66/100 Step 40/50 | D: 0.0056 | G: 0.0984\n",
      "[Attentive ESRGAN] Epoch 66 VAL | PSNR: 22.35 dB | SSIM: 0.5988\n",
      "[Attentive ESRGAN] Epoch 66 done in 166.3s | D: 0.0122 | G: 0.0992\n",
      "[Attentive ESRGAN] Epoch 67/100 Step 0/50 | D: 0.0234 | G: 0.1013\n",
      "[Attentive ESRGAN] Epoch 67/100 Step 10/50 | D: 0.0008 | G: 0.1336\n",
      "[Attentive ESRGAN] Epoch 67/100 Step 20/50 | D: 0.0045 | G: 0.0699\n",
      "[Attentive ESRGAN] Epoch 67/100 Step 30/50 | D: 0.0013 | G: 0.1273\n",
      "[Attentive ESRGAN] Epoch 67/100 Step 40/50 | D: 0.0053 | G: 0.0852\n",
      "[Attentive ESRGAN] Epoch 67 VAL | PSNR: 22.84 dB | SSIM: 0.6291\n",
      "[Attentive ESRGAN] Epoch 67 done in 166.6s | D: 0.0053 | G: 0.1037\n",
      "[Attentive ESRGAN] Epoch 68/100 Step 0/50 | D: 0.0024 | G: 0.1770\n",
      "[Attentive ESRGAN] Epoch 68/100 Step 10/50 | D: 0.0227 | G: 0.0863\n",
      "[Attentive ESRGAN] Epoch 68/100 Step 20/50 | D: 0.0028 | G: 0.0985\n",
      "[Attentive ESRGAN] Epoch 68/100 Step 30/50 | D: 0.0021 | G: 0.1474\n",
      "[Attentive ESRGAN] Epoch 68/100 Step 40/50 | D: 0.0018 | G: 0.1164\n",
      "[Attentive ESRGAN] Epoch 68 VAL | PSNR: 22.98 dB | SSIM: 0.6425\n",
      "[Attentive ESRGAN] Epoch 68 done in 166.8s | D: 0.0051 | G: 0.1119\n",
      "[Attentive ESRGAN] Epoch 69/100 Step 0/50 | D: 0.0044 | G: 0.0687\n",
      "[Attentive ESRGAN] Epoch 69/100 Step 10/50 | D: 0.0028 | G: 0.0812\n",
      "[Attentive ESRGAN] Epoch 69/100 Step 20/50 | D: 0.0254 | G: 0.0914\n",
      "[Attentive ESRGAN] Epoch 69/100 Step 30/50 | D: 0.0026 | G: 0.1099\n",
      "[Attentive ESRGAN] Epoch 69/100 Step 40/50 | D: 0.0013 | G: 0.1204\n",
      "[Attentive ESRGAN] Epoch 69 VAL | PSNR: 21.28 dB | SSIM: 0.5932\n",
      "[Attentive ESRGAN] Epoch 69 done in 167.3s | D: 0.0092 | G: 0.1037\n",
      "[Attentive ESRGAN] Epoch 70/100 Step 0/50 | D: 0.0023 | G: 0.1337\n",
      "[Attentive ESRGAN] Epoch 70/100 Step 10/50 | D: 0.0013 | G: 0.1105\n",
      "[Attentive ESRGAN] Epoch 70/100 Step 20/50 | D: 0.0051 | G: 0.1042\n",
      "[Attentive ESRGAN] Epoch 70/100 Step 30/50 | D: 0.0135 | G: 0.1644\n",
      "[Attentive ESRGAN] Epoch 70/100 Step 40/50 | D: 0.0134 | G: 0.1009\n",
      "[Attentive ESRGAN] Epoch 70 VAL | PSNR: 23.80 dB | SSIM: 0.6417\n",
      "[Attentive ESRGAN] Epoch 70 done in 167.1s | D: 0.0084 | G: 0.1100\n",
      "[Attentive ESRGAN] Epoch 71/100 Step 0/50 | D: 0.0074 | G: 0.0662\n",
      "[Attentive ESRGAN] Epoch 71/100 Step 10/50 | D: 0.0012 | G: 0.0855\n",
      "[Attentive ESRGAN] Epoch 71/100 Step 20/50 | D: 0.0065 | G: 0.0833\n",
      "[Attentive ESRGAN] Epoch 71/100 Step 30/50 | D: 0.0005 | G: 0.1813\n",
      "[Attentive ESRGAN] Epoch 71/100 Step 40/50 | D: 0.0007 | G: 0.0900\n",
      "[Attentive ESRGAN] Epoch 71 VAL | PSNR: 22.38 dB | SSIM: 0.6113\n",
      "[Attentive ESRGAN] Epoch 71 done in 168.0s | D: 0.0043 | G: 0.1110\n",
      "[Attentive ESRGAN] Epoch 72/100 Step 0/50 | D: 0.0109 | G: 0.0984\n",
      "[Attentive ESRGAN] Epoch 72/100 Step 10/50 | D: 0.0304 | G: 0.0823\n",
      "[Attentive ESRGAN] Epoch 72/100 Step 20/50 | D: 0.0061 | G: 0.0834\n",
      "[Attentive ESRGAN] Epoch 72/100 Step 30/50 | D: 0.0013 | G: 0.1153\n",
      "[Attentive ESRGAN] Epoch 72/100 Step 40/50 | D: 0.0035 | G: 0.1276\n",
      "[Attentive ESRGAN] Epoch 72 VAL | PSNR: 21.48 dB | SSIM: 0.5792\n",
      "[Attentive ESRGAN] Epoch 72 done in 166.5s | D: 0.0067 | G: 0.1044\n",
      "[Attentive ESRGAN] Epoch 73/100 Step 0/50 | D: 0.0043 | G: 0.1023\n",
      "[Attentive ESRGAN] Epoch 73/100 Step 10/50 | D: 0.0224 | G: 0.0952\n",
      "[Attentive ESRGAN] Epoch 73/100 Step 20/50 | D: 0.0019 | G: 0.0721\n",
      "[Attentive ESRGAN] Epoch 73/100 Step 30/50 | D: 0.0067 | G: 0.1342\n",
      "[Attentive ESRGAN] Epoch 73/100 Step 40/50 | D: 0.0013 | G: 0.1086\n",
      "[Attentive ESRGAN] Epoch 73 VAL | PSNR: 21.97 dB | SSIM: 0.6102\n",
      "[Attentive ESRGAN] Epoch 73 done in 167.2s | D: 0.0067 | G: 0.1074\n",
      "[Attentive ESRGAN] Epoch 74/100 Step 0/50 | D: 0.0019 | G: 0.0771\n",
      "[Attentive ESRGAN] Epoch 74/100 Step 10/50 | D: 0.0063 | G: 0.1010\n",
      "[Attentive ESRGAN] Epoch 74/100 Step 20/50 | D: 0.0050 | G: 0.0960\n",
      "[Attentive ESRGAN] Epoch 74/100 Step 30/50 | D: 0.0103 | G: 0.1234\n",
      "[Attentive ESRGAN] Epoch 74/100 Step 40/50 | D: 0.0011 | G: 0.1116\n",
      "[Attentive ESRGAN] Epoch 74 VAL | PSNR: 22.42 dB | SSIM: 0.6191\n",
      "[Attentive ESRGAN] Epoch 74 done in 167.0s | D: 0.0071 | G: 0.1046\n",
      "[Attentive ESRGAN] Epoch 75/100 Step 0/50 | D: 0.0028 | G: 0.0736\n",
      "[Attentive ESRGAN] Epoch 75/100 Step 10/50 | D: 0.0038 | G: 0.0704\n",
      "[Attentive ESRGAN] Epoch 75/100 Step 20/50 | D: 0.0013 | G: 0.0960\n",
      "[Attentive ESRGAN] Epoch 75/100 Step 30/50 | D: 0.0164 | G: 0.1074\n",
      "[Attentive ESRGAN] Epoch 75/100 Step 40/50 | D: 0.0010 | G: 0.0751\n",
      "[Attentive ESRGAN] Epoch 75 VAL | PSNR: 22.01 dB | SSIM: 0.6035\n",
      "[Attentive ESRGAN] Epoch 75 done in 166.6s | D: 0.0057 | G: 0.1002\n",
      "[Attentive ESRGAN] Epoch 76/100 Step 0/50 | D: 0.0074 | G: 0.0900\n",
      "[Attentive ESRGAN] Epoch 76/100 Step 10/50 | D: 0.0010 | G: 0.0541\n",
      "[Attentive ESRGAN] Epoch 76/100 Step 20/50 | D: 0.0004 | G: 0.0805\n",
      "[Attentive ESRGAN] Epoch 76/100 Step 30/50 | D: 0.0062 | G: 0.1552\n",
      "[Attentive ESRGAN] Epoch 76/100 Step 40/50 | D: 0.0010 | G: 0.0988\n",
      "[Attentive ESRGAN] Epoch 76 VAL | PSNR: 22.74 dB | SSIM: 0.5948\n",
      "[Attentive ESRGAN] Epoch 76 done in 166.2s | D: 0.0072 | G: 0.1001\n",
      "[Attentive ESRGAN] Epoch 77/100 Step 0/50 | D: 0.0229 | G: 0.0645\n",
      "[Attentive ESRGAN] Epoch 77/100 Step 10/50 | D: 0.0040 | G: 0.0810\n",
      "[Attentive ESRGAN] Epoch 77/100 Step 20/50 | D: 0.0044 | G: 0.0821\n",
      "[Attentive ESRGAN] Epoch 77/100 Step 30/50 | D: 0.0039 | G: 0.1151\n",
      "[Attentive ESRGAN] Epoch 77/100 Step 40/50 | D: 0.0004 | G: 0.1261\n",
      "[Attentive ESRGAN] Epoch 77 VAL | PSNR: 23.43 dB | SSIM: 0.6122\n",
      "[Attentive ESRGAN] Epoch 77 done in 166.9s | D: 0.0053 | G: 0.0996\n",
      "[Attentive ESRGAN] Epoch 78/100 Step 0/50 | D: 0.0007 | G: 0.1006\n",
      "[Attentive ESRGAN] Epoch 78/100 Step 10/50 | D: 0.0228 | G: 0.0805\n",
      "[Attentive ESRGAN] Epoch 78/100 Step 20/50 | D: 0.0024 | G: 0.0940\n",
      "[Attentive ESRGAN] Epoch 78/100 Step 30/50 | D: 0.0009 | G: 0.1463\n",
      "[Attentive ESRGAN] Epoch 78/100 Step 40/50 | D: 0.0111 | G: 0.1182\n",
      "[Attentive ESRGAN] Epoch 78 VAL | PSNR: 23.03 dB | SSIM: 0.6062\n",
      "[Attentive ESRGAN] Epoch 78 done in 166.1s | D: 0.0110 | G: 0.1077\n",
      "[Attentive ESRGAN] Epoch 79/100 Step 0/50 | D: 0.0050 | G: 0.0893\n",
      "[Attentive ESRGAN] Epoch 79/100 Step 10/50 | D: 0.0012 | G: 0.0843\n",
      "[Attentive ESRGAN] Epoch 79/100 Step 20/50 | D: 0.0039 | G: 0.0575\n",
      "[Attentive ESRGAN] Epoch 79/100 Step 30/50 | D: 0.0087 | G: 0.1165\n",
      "[Attentive ESRGAN] Epoch 79/100 Step 40/50 | D: 0.0017 | G: 0.0974\n",
      "[Attentive ESRGAN] Epoch 79 VAL | PSNR: 22.49 dB | SSIM: 0.6142\n",
      "[Attentive ESRGAN] Epoch 79 done in 166.3s | D: 0.0081 | G: 0.1033\n",
      "[Attentive ESRGAN] Epoch 80/100 Step 0/50 | D: 0.0022 | G: 0.0995\n",
      "[Attentive ESRGAN] Epoch 80/100 Step 10/50 | D: 0.0013 | G: 0.0710\n",
      "[Attentive ESRGAN] Epoch 80/100 Step 20/50 | D: 0.0011 | G: 0.0877\n",
      "[Attentive ESRGAN] Epoch 80/100 Step 30/50 | D: 0.0011 | G: 0.1249\n",
      "[Attentive ESRGAN] Epoch 80/100 Step 40/50 | D: 0.0014 | G: 0.1144\n",
      "[Attentive ESRGAN] Epoch 80 VAL | PSNR: 21.99 dB | SSIM: 0.6091\n",
      "[Attentive ESRGAN] Epoch 80 done in 165.6s | D: 0.0079 | G: 0.1055\n",
      "[Attentive ESRGAN] Epoch 81/100 Step 0/50 | D: 0.0354 | G: 0.0547\n",
      "[Attentive ESRGAN] Epoch 81/100 Step 10/50 | D: 0.0071 | G: 0.0541\n",
      "[Attentive ESRGAN] Epoch 81/100 Step 20/50 | D: 0.0062 | G: 0.1108\n",
      "[Attentive ESRGAN] Epoch 81/100 Step 30/50 | D: 0.0223 | G: 0.1454\n",
      "[Attentive ESRGAN] Epoch 81/100 Step 40/50 | D: 0.0029 | G: 0.1600\n",
      "[Attentive ESRGAN] Epoch 81 VAL | PSNR: 22.32 dB | SSIM: 0.6122\n",
      "[Attentive ESRGAN] Epoch 81 done in 165.7s | D: 0.0124 | G: 0.0993\n",
      "[Attentive ESRGAN] Epoch 82/100 Step 0/50 | D: 0.0015 | G: 0.0499\n",
      "[Attentive ESRGAN] Epoch 82/100 Step 10/50 | D: 0.0161 | G: 0.1012\n",
      "[Attentive ESRGAN] Epoch 82/100 Step 20/50 | D: 0.0148 | G: 0.1044\n",
      "[Attentive ESRGAN] Epoch 82/100 Step 30/50 | D: 0.0057 | G: 0.1316\n",
      "[Attentive ESRGAN] Epoch 82/100 Step 40/50 | D: 0.0041 | G: 0.0937\n",
      "[Attentive ESRGAN] Epoch 82 VAL | PSNR: 23.10 dB | SSIM: 0.5756\n",
      "[Attentive ESRGAN] Epoch 82 done in 166.3s | D: 0.0092 | G: 0.1067\n",
      "[Attentive ESRGAN] Epoch 83/100 Step 0/50 | D: 0.0193 | G: 0.0941\n",
      "[Attentive ESRGAN] Epoch 83/100 Step 10/50 | D: 0.0048 | G: 0.1299\n",
      "[Attentive ESRGAN] Epoch 83/100 Step 20/50 | D: 0.0120 | G: 0.0948\n",
      "[Attentive ESRGAN] Epoch 83/100 Step 30/50 | D: 0.0055 | G: 0.1170\n",
      "[Attentive ESRGAN] Epoch 83/100 Step 40/50 | D: 0.0015 | G: 0.0949\n",
      "[Attentive ESRGAN] Epoch 83 VAL | PSNR: 22.86 dB | SSIM: 0.6160\n",
      "[Attentive ESRGAN] Epoch 83 done in 166.0s | D: 0.0106 | G: 0.0994\n",
      "[Attentive ESRGAN] Epoch 84/100 Step 0/50 | D: 0.0115 | G: 0.0971\n",
      "[Attentive ESRGAN] Epoch 84/100 Step 10/50 | D: 0.0191 | G: 0.1022\n",
      "[Attentive ESRGAN] Epoch 84/100 Step 20/50 | D: 0.0037 | G: 0.0795\n",
      "[Attentive ESRGAN] Epoch 84/100 Step 30/50 | D: 0.0150 | G: 0.1116\n",
      "[Attentive ESRGAN] Epoch 84/100 Step 40/50 | D: 0.0250 | G: 0.0878\n",
      "[Attentive ESRGAN] Epoch 84 VAL | PSNR: 22.38 dB | SSIM: 0.6110\n",
      "[Attentive ESRGAN] Epoch 84 done in 165.3s | D: 0.0159 | G: 0.1045\n",
      "[Attentive ESRGAN] Epoch 85/100 Step 0/50 | D: 0.0033 | G: 0.0681\n",
      "[Attentive ESRGAN] Epoch 85/100 Step 10/50 | D: 0.0012 | G: 0.0720\n",
      "[Attentive ESRGAN] Epoch 85/100 Step 20/50 | D: 0.0033 | G: 0.1006\n",
      "[Attentive ESRGAN] Epoch 85/100 Step 30/50 | D: 0.0026 | G: 0.1115\n",
      "[Attentive ESRGAN] Epoch 85/100 Step 40/50 | D: 0.0055 | G: 0.0885\n",
      "[Attentive ESRGAN] Epoch 85 VAL | PSNR: 22.37 dB | SSIM: 0.5932\n",
      "[Attentive ESRGAN] Epoch 85 done in 165.3s | D: 0.0052 | G: 0.1076\n",
      "[Attentive ESRGAN] Epoch 86/100 Step 0/50 | D: 0.0091 | G: 0.0557\n",
      "[Attentive ESRGAN] Epoch 86/100 Step 10/50 | D: 0.0145 | G: 0.0652\n",
      "[Attentive ESRGAN] Epoch 86/100 Step 20/50 | D: 0.0176 | G: 0.0655\n",
      "[Attentive ESRGAN] Epoch 86/100 Step 30/50 | D: 0.0017 | G: 0.1391\n",
      "[Attentive ESRGAN] Epoch 86/100 Step 40/50 | D: 0.0045 | G: 0.0973\n",
      "[Attentive ESRGAN] Epoch 86 VAL | PSNR: 22.19 dB | SSIM: 0.6118\n",
      "[Attentive ESRGAN] Epoch 86 done in 165.2s | D: 0.0114 | G: 0.1052\n",
      "[Attentive ESRGAN] Epoch 87/100 Step 0/50 | D: 0.0221 | G: 0.1149\n",
      "[Attentive ESRGAN] Epoch 87/100 Step 10/50 | D: 0.0296 | G: 0.1283\n",
      "[Attentive ESRGAN] Epoch 87/100 Step 20/50 | D: 0.0224 | G: 0.0835\n",
      "[Attentive ESRGAN] Epoch 87/100 Step 30/50 | D: 0.0019 | G: 0.1663\n",
      "[Attentive ESRGAN] Epoch 87/100 Step 40/50 | D: 0.0039 | G: 0.0891\n",
      "[Attentive ESRGAN] Epoch 87 VAL | PSNR: 22.23 dB | SSIM: 0.6100\n",
      "[Attentive ESRGAN] Epoch 87 done in 166.6s | D: 0.0127 | G: 0.1012\n",
      "[Attentive ESRGAN] Epoch 88/100 Step 0/50 | D: 0.0099 | G: 0.0555\n",
      "[Attentive ESRGAN] Epoch 88/100 Step 10/50 | D: 0.0016 | G: 0.0731\n",
      "[Attentive ESRGAN] Epoch 88/100 Step 20/50 | D: 0.0058 | G: 0.1291\n",
      "[Attentive ESRGAN] Epoch 88/100 Step 30/50 | D: 0.0015 | G: 0.1067\n",
      "[Attentive ESRGAN] Epoch 88/100 Step 40/50 | D: 0.0211 | G: 0.0841\n",
      "[Attentive ESRGAN] Epoch 88 VAL | PSNR: 22.06 dB | SSIM: 0.5794\n",
      "[Attentive ESRGAN] Epoch 88 done in 166.6s | D: 0.0102 | G: 0.0976\n",
      "[Attentive ESRGAN] Epoch 89/100 Step 0/50 | D: 0.0123 | G: 0.0596\n",
      "[Attentive ESRGAN] Epoch 89/100 Step 10/50 | D: 0.0147 | G: 0.0893\n",
      "[Attentive ESRGAN] Epoch 89/100 Step 20/50 | D: 0.0041 | G: 0.0760\n",
      "[Attentive ESRGAN] Epoch 89/100 Step 30/50 | D: 0.0082 | G: 0.0951\n",
      "[Attentive ESRGAN] Epoch 89/100 Step 40/50 | D: 0.0027 | G: 0.1433\n",
      "[Attentive ESRGAN] Epoch 89 VAL | PSNR: 21.81 dB | SSIM: 0.5738\n",
      "[Attentive ESRGAN] Epoch 89 done in 165.5s | D: 0.0089 | G: 0.1015\n",
      "[Attentive ESRGAN] Epoch 90/100 Step 0/50 | D: 0.0173 | G: 0.0972\n",
      "[Attentive ESRGAN] Epoch 90/100 Step 10/50 | D: 0.0079 | G: 0.1029\n",
      "[Attentive ESRGAN] Epoch 90/100 Step 20/50 | D: 0.0017 | G: 0.1098\n",
      "[Attentive ESRGAN] Epoch 90/100 Step 30/50 | D: 0.0007 | G: 0.1746\n",
      "[Attentive ESRGAN] Epoch 90/100 Step 40/50 | D: 0.0021 | G: 0.1261\n",
      "[Attentive ESRGAN] Epoch 90 VAL | PSNR: 22.35 dB | SSIM: 0.6187\n",
      "[Attentive ESRGAN] Epoch 90 done in 165.6s | D: 0.0081 | G: 0.1019\n",
      "[Attentive ESRGAN] Epoch 91/100 Step 0/50 | D: 0.0064 | G: 0.1380\n",
      "[Attentive ESRGAN] Epoch 91/100 Step 10/50 | D: 0.0048 | G: 0.0976\n",
      "[Attentive ESRGAN] Epoch 91/100 Step 20/50 | D: 0.0022 | G: 0.0780\n",
      "[Attentive ESRGAN] Epoch 91/100 Step 30/50 | D: 0.0027 | G: 0.1125\n",
      "[Attentive ESRGAN] Epoch 91/100 Step 40/50 | D: 0.0039 | G: 0.0790\n",
      "[Attentive ESRGAN] Epoch 91 VAL | PSNR: 22.18 dB | SSIM: 0.6034\n",
      "[Attentive ESRGAN] Epoch 91 done in 167.2s | D: 0.0061 | G: 0.1003\n",
      "[Attentive ESRGAN] Epoch 92/100 Step 0/50 | D: 0.0141 | G: 0.0741\n",
      "[Attentive ESRGAN] Epoch 92/100 Step 10/50 | D: 0.0026 | G: 0.1200\n",
      "[Attentive ESRGAN] Epoch 92/100 Step 20/50 | D: 0.0066 | G: 0.1061\n",
      "[Attentive ESRGAN] Epoch 92/100 Step 30/50 | D: 0.0551 | G: 0.1367\n",
      "[Attentive ESRGAN] Epoch 92/100 Step 40/50 | D: 0.0040 | G: 0.1293\n",
      "[Attentive ESRGAN] Epoch 92 VAL | PSNR: 23.00 dB | SSIM: 0.6037\n",
      "[Attentive ESRGAN] Epoch 92 done in 166.4s | D: 0.0168 | G: 0.1016\n",
      "[Attentive ESRGAN] Epoch 93/100 Step 0/50 | D: 0.0250 | G: 0.0761\n",
      "[Attentive ESRGAN] Epoch 93/100 Step 10/50 | D: 0.0117 | G: 0.1204\n",
      "[Attentive ESRGAN] Epoch 93/100 Step 20/50 | D: 0.0152 | G: 0.0868\n",
      "[Attentive ESRGAN] Epoch 93/100 Step 30/50 | D: 0.0033 | G: 0.0986\n",
      "[Attentive ESRGAN] Epoch 93/100 Step 40/50 | D: 0.0577 | G: 0.0892\n",
      "[Attentive ESRGAN] Epoch 93 VAL | PSNR: 22.91 dB | SSIM: 0.6261\n",
      "[Attentive ESRGAN] Epoch 93 done in 166.0s | D: 0.0256 | G: 0.0979\n",
      "[Attentive ESRGAN] Epoch 94/100 Step 0/50 | D: 0.0607 | G: 0.0942\n",
      "[Attentive ESRGAN] Epoch 94/100 Step 10/50 | D: 0.0062 | G: 0.0744\n",
      "[Attentive ESRGAN] Epoch 94/100 Step 20/50 | D: 0.0105 | G: 0.1367\n",
      "[Attentive ESRGAN] Epoch 94/100 Step 30/50 | D: 0.0102 | G: 0.1900\n",
      "[Attentive ESRGAN] Epoch 94/100 Step 40/50 | D: 0.0097 | G: 0.1279\n",
      "[Attentive ESRGAN] Epoch 94 VAL | PSNR: 22.65 dB | SSIM: 0.5983\n",
      "[Attentive ESRGAN] Epoch 94 done in 166.7s | D: 0.0082 | G: 0.1071\n",
      "[Attentive ESRGAN] Epoch 95/100 Step 0/50 | D: 0.0090 | G: 0.0680\n",
      "[Attentive ESRGAN] Epoch 95/100 Step 10/50 | D: 0.0140 | G: 0.0809\n",
      "[Attentive ESRGAN] Epoch 95/100 Step 20/50 | D: 0.0326 | G: 0.0950\n",
      "[Attentive ESRGAN] Epoch 95/100 Step 30/50 | D: 0.0025 | G: 0.1072\n",
      "[Attentive ESRGAN] Epoch 95/100 Step 40/50 | D: 0.0255 | G: 0.1050\n",
      "[Attentive ESRGAN] Epoch 95 VAL | PSNR: 21.95 dB | SSIM: 0.6138\n",
      "[Attentive ESRGAN] Epoch 95 done in 166.5s | D: 0.0147 | G: 0.1076\n",
      "[Attentive ESRGAN] Epoch 96/100 Step 0/50 | D: 0.0030 | G: 0.0843\n",
      "[Attentive ESRGAN] Epoch 96/100 Step 10/50 | D: 0.0022 | G: 0.0782\n",
      "[Attentive ESRGAN] Epoch 96/100 Step 20/50 | D: 0.0051 | G: 0.0552\n",
      "[Attentive ESRGAN] Epoch 96/100 Step 30/50 | D: 0.0051 | G: 0.1227\n",
      "[Attentive ESRGAN] Epoch 96/100 Step 40/50 | D: 0.0090 | G: 0.1157\n",
      "[Attentive ESRGAN] Epoch 96 VAL | PSNR: 22.98 dB | SSIM: 0.6203\n",
      "[Attentive ESRGAN] Epoch 96 done in 168.3s | D: 0.0053 | G: 0.0988\n",
      "[Attentive ESRGAN] Epoch 97/100 Step 0/50 | D: 0.0055 | G: 0.1048\n",
      "[Attentive ESRGAN] Epoch 97/100 Step 10/50 | D: 0.0556 | G: 0.1166\n",
      "[Attentive ESRGAN] Epoch 97/100 Step 20/50 | D: 0.0005 | G: 0.0935\n",
      "[Attentive ESRGAN] Epoch 97/100 Step 30/50 | D: 0.0052 | G: 0.1333\n",
      "[Attentive ESRGAN] Epoch 97/100 Step 40/50 | D: 0.0046 | G: 0.0601\n",
      "[Attentive ESRGAN] Epoch 97 VAL | PSNR: 22.81 dB | SSIM: 0.6073\n",
      "[Attentive ESRGAN] Epoch 97 done in 167.8s | D: 0.0114 | G: 0.1014\n",
      "[Attentive ESRGAN] Epoch 98/100 Step 0/50 | D: 0.0007 | G: 0.0812\n",
      "[Attentive ESRGAN] Epoch 98/100 Step 10/50 | D: 0.0094 | G: 0.0967\n",
      "[Attentive ESRGAN] Epoch 98/100 Step 20/50 | D: 0.0097 | G: 0.0952\n",
      "[Attentive ESRGAN] Epoch 98/100 Step 30/50 | D: 0.0017 | G: 0.1519\n",
      "[Attentive ESRGAN] Epoch 98/100 Step 40/50 | D: 0.0010 | G: 0.1179\n",
      "[Attentive ESRGAN] Epoch 98 VAL | PSNR: 23.55 dB | SSIM: 0.6337\n",
      "[Attentive ESRGAN] Epoch 98 done in 167.8s | D: 0.0032 | G: 0.0999\n",
      "[Attentive ESRGAN] Epoch 99/100 Step 0/50 | D: 0.0052 | G: 0.1037\n",
      "[Attentive ESRGAN] Epoch 99/100 Step 10/50 | D: 0.0134 | G: 0.0525\n",
      "[Attentive ESRGAN] Epoch 99/100 Step 20/50 | D: 0.0074 | G: 0.0717\n",
      "[Attentive ESRGAN] Epoch 99/100 Step 30/50 | D: 0.0007 | G: 0.0924\n",
      "[Attentive ESRGAN] Epoch 99/100 Step 40/50 | D: 0.0010 | G: 0.1191\n",
      "[Attentive ESRGAN] Epoch 99 VAL | PSNR: 23.78 dB | SSIM: 0.6451\n",
      "[Attentive ESRGAN] Epoch 99 done in 167.4s | D: 0.0059 | G: 0.1010\n",
      "[Attentive ESRGAN] Epoch 100/100 Step 0/50 | D: 0.0074 | G: 0.0477\n",
      "[Attentive ESRGAN] Epoch 100/100 Step 10/50 | D: 0.0046 | G: 0.0800\n",
      "[Attentive ESRGAN] Epoch 100/100 Step 20/50 | D: 0.0011 | G: 0.1002\n",
      "[Attentive ESRGAN] Epoch 100/100 Step 30/50 | D: 0.0011 | G: 0.1274\n",
      "[Attentive ESRGAN] Epoch 100/100 Step 40/50 | D: 0.0046 | G: 0.0869\n",
      "[Attentive ESRGAN] Epoch 100 VAL | PSNR: 23.54 dB | SSIM: 0.6011\n",
      "[Attentive ESRGAN] Epoch 100 done in 168.4s | D: 0.0104 | G: 0.1061\n",
      "[Attentive ESRGAN] Training complete.\n"
     ]
    }
   ],
   "source": [
    "att_gen = build_attentive_generator(scale=UPSCALE, num_res_blocks=16)\n",
    "att_gen.load_weights(ATTENTIVE_WARMUP_PATH)\n",
    "att_disc = build_relativistic_discriminator(input_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "vgg_esr = build_vgg(hr_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "\n",
    "att_history = train_attentive_esrgan(\n",
    "    generator=att_gen,\n",
    "    discriminator=att_disc,\n",
    "    vgg=vgg_esr,\n",
    "    train_loader=train_gen,\n",
    "    val_loader=val_gen,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:28:44.210690Z",
     "iopub.status.busy": "2025-12-12T10:28:44.209975Z",
     "iopub.status.idle": "2025-12-12T10:28:44.215480Z",
     "shell.execute_reply": "2025-12-12T10:28:44.214893Z",
     "shell.execute_reply.started": "2025-12-12T10:28:44.210667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# --- Saving the dictionary to a .json file ---\n",
    "with open('esrgan_history.json', 'w') as json_file:\n",
    "    json.dump(att_history, json_file, indent=4) # 'indent' makes the file human-readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_gan_history(history, title_prefix=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot D/G loss and optional validation PSNR/SSIM vs epoch.\n",
    "    history: dict returned by train_srgan_baseline / train_attentive_esrgan.\n",
    "    \"\"\"\n",
    "    epochs = history.get(\"epoch\", list(range(1, len(history.get(\"d_loss\", [])) + 1)))\n",
    "\n",
    "    # ---- 1) Loss curves ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, history[\"d_loss\"], label=\"D loss\")\n",
    "    plt.plot(epochs, history[\"g_loss\"], label=\"G loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title_prefix} Training Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 2) Validation metrics (if available) ----\n",
    "    if \"val_psnr\" in history and \"val_ssim\" in history:\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"PSNR (dB)\", color=\"tab:blue\")\n",
    "        ax1.plot(epochs, history[\"val_psnr\"], marker=\"o\", label=\"PSNR\", color=\"tab:blue\")\n",
    "        ax1.tick_params(axis='y', labelcolor=\"tab:blue\")\n",
    "        ax1.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel(\"SSIM\", color=\"tab:orange\")\n",
    "        ax2.plot(epochs, history[\"val_ssim\"], marker=\"s\", label=\"SSIM\", color=\"tab:orange\")\n",
    "        ax2.tick_params(axis='y', labelcolor=\"tab:orange\")\n",
    "\n",
    "        plt.title(f\"{title_prefix} Validation Metrics\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_gan_history(srgan_history, title_prefix=\"SRGAN Baseline\")\n",
    "plot_gan_history(att_history, title_prefix=\"Attentive ESRGAN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-12T04:03:38.654591Z",
     "iopub.status.idle": "2025-12-12T04:03:38.654855Z",
     "shell.execute_reply": "2025-12-12T04:03:38.654731Z",
     "shell.execute_reply.started": "2025-12-12T04:03:38.654718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compare_two_gan_models(gen_a,\n",
    "                           gen_b,\n",
    "                           label_a=\"Model A\",\n",
    "                           label_b=\"Model B\",\n",
    "                           image_path=None,\n",
    "                           scale_factor=4):\n",
    "    \"\"\"\n",
    "    Compare two GAN-based SR models (tanh output in [-1,1]) on the same image.\n",
    "    Shows: Bicubic, Model A, Model B, Ground Truth\n",
    "    and prints PSNR/SSIM for each model.\n",
    "    \"\"\"\n",
    "    if image_path is None:\n",
    "        print(\"Please provide image_path.\")\n",
    "        return\n",
    "\n",
    "    # 1. Load HR image\n",
    "    hr_img = cv2.imread(image_path)\n",
    "    if hr_img is None:\n",
    "        print(f\"[Compare] Could not load image: {image_path}\")\n",
    "        return\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = hr_img.shape\n",
    "    h, w = (h // scale_factor) * scale_factor, (w // scale_factor) * scale_factor\n",
    "    hr_img = hr_img[:h, :w, :]\n",
    "\n",
    "    # 2. Create LR\n",
    "    lr_shape = (w // scale_factor, h // scale_factor)\n",
    "    lr_img_small = cv2.resize(hr_img, lr_shape, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 3. Prepare input [-1,1] for both models\n",
    "    lr_01 = lr_img_small.astype(np.float32) / 255.0\n",
    "    lr_in = lr_01 * 2.0 - 1.0\n",
    "    inp_batch = np.expand_dims(lr_in, axis=0)\n",
    "\n",
    "    # 4. Run both models\n",
    "    sr_a = gen_a.predict(inp_batch, verbose=0)[0]    # [-1,1]\n",
    "    sr_b = gen_b.predict(inp_batch, verbose=0)[0]    # [-1,1]\n",
    "\n",
    "    sr_a_01 = np.clip((sr_a + 1.0) / 2.0, 0.0, 1.0)\n",
    "    sr_b_01 = np.clip((sr_b + 1.0) / 2.0, 0.0, 1.0)\n",
    "\n",
    "    bicubic = cv2.resize(lr_img_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    bicubic = bicubic.astype(np.float32) / 255.0\n",
    "    hr_01 = hr_img.astype(np.float32) / 255.0\n",
    "\n",
    "    # 5. Compute metrics\n",
    "    def _metrics(sr_img_01):\n",
    "        tf_hr = tf.convert_to_tensor(hr_01, tf.float32)\n",
    "        tf_sr = tf.convert_to_tensor(sr_img_01, tf.float32)\n",
    "        psnr = tf.image.psnr(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "        ssim = tf.image.ssim(tf_hr, tf_sr, max_val=1.0).numpy()\n",
    "        return psnr, ssim\n",
    "\n",
    "    psnr_bic, ssim_bic = _metrics(bicubic)\n",
    "    psnr_a, ssim_a = _metrics(sr_a_01)\n",
    "    psnr_b, ssim_b = _metrics(sr_b_01)\n",
    "\n",
    "    print(f\"[Bicubic]   PSNR: {psnr_bic:.2f} dB | SSIM: {ssim_bic:.4f}\")\n",
    "    print(f\"[{label_a}] PSNR: {psnr_a:.2f} dB | SSIM: {ssim_a:.4f}\")\n",
    "    print(f\"[{label_b}] PSNR: {psnr_b:.2f} dB | SSIM: {ssim_b:.4f}\")\n",
    "\n",
    "    # 6. Plot\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(28, 8))\n",
    "\n",
    "    axes[0].imshow(bicubic)\n",
    "    axes[0].set_title(f\"Bicubic\\nPSNR: {psnr_bic:.2f} | SSIM: {ssim_bic:.4f}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sr_a_01)\n",
    "    axes[1].set_title(f\"{label_a}\\nPSNR: {psnr_a:.2f} | SSIM: {ssim_a:.4f}\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(sr_b_01)\n",
    "    axes[2].set_title(f\"{label_b}\\nPSNR: {psnr_b:.2f} | SSIM: {ssim_b:.4f}\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    axes[3].imshow(hr_01)\n",
    "    axes[3].set_title(\"Ground Truth\")\n",
    "    axes[3].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-12T04:03:38.656328Z",
     "iopub.status.idle": "2025-12-12T04:03:38.656625Z",
     "shell.execute_reply": "2025-12-12T04:03:38.656480Z",
     "shell.execute_reply.started": "2025-12-12T04:03:38.656465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_y_dir = \"/kaggle/input/super-resolution-test-cases/test cases\"\n",
    "test_files = sorted(os.listdir(test_y_dir))\n",
    "img_path = os.path.join(test_y_dir, test_files[0])\n",
    "\n",
    "compare_two_gan_models(\n",
    "    gen_a=srgan_gen,\n",
    "    gen_b=att_gen,\n",
    "    label_a=\"SRGAN Baseline\",\n",
    "    label_b=\"Attentive ESRGAN\",\n",
    "    image_path=img_path,\n",
    "    scale_factor=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-12T04:03:38.657715Z",
     "iopub.status.idle": "2025-12-12T04:03:38.657979Z",
     "shell.execute_reply": "2025-12-12T04:03:38.657869Z",
     "shell.execute_reply.started": "2025-12-12T04:03:38.657856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # 5. Example usage (comment/uncomment as needed)\n",
    "# # ============================================================\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Setup complete. Edit this block to run training/inference.\")\n",
    "\n",
    "#     # Example test images dir (must add this dataset in Kaggle \"Data\" tab)\n",
    "#     test_y_dir = \"/kaggle/input/super-resolution-test-cases/test cases\"\n",
    "#     test_files = sorted(os.listdir(test_y_dir)) if os.path.exists(test_y_dir) else []\n",
    "\n",
    "#     # ---------- 1) SRCNN baseline ----------\n",
    "#     # srcnn = build_srcnn()\n",
    "#     # try:\n",
    "#     #     srcnn = keras.models.load_model(SRCNN_PRETRAINED_PATH, compile=False)\n",
    "#     #     print(\"Loaded pretrained SRCNN from:\", SRCNN_PRETRAINED_PATH)\n",
    "#     # except Exception as e:\n",
    "#     #     print(\"Could not load pretrained SRCNN:\", e)\n",
    "#     #\n",
    "#     # if test_files:\n",
    "#     #     img_path = os.path.join(test_y_dir, test_files[0])\n",
    "#     #     predict_srcnn_full_image(srcnn, img_path)\n",
    "\n",
    "#     # ---------- 2) SRGAN baseline ----------\n",
    "#     # srgan_gen = build_srgan_generator(scale=UPSCALE, num_res_blocks=16)\n",
    "#     # srgan_disc = build_srgan_discriminator(input_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "#     # vgg = build_vgg(hr_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "#     # srgan_disc.compile(loss='binary_crossentropy',\n",
    "#     #                    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#     #                    metrics=['accuracy'])\n",
    "#     # srgan_combined = build_srgan_combined(srgan_gen, srgan_disc, vgg,\n",
    "#     #                                       lr_shape=(LR_CROP_SIZE, LR_CROP_SIZE, 3))\n",
    "#     #\n",
    "#     # try:\n",
    "#     #     srgan_gen.load_weights(SRRESNET_WARMUP_PATH)\n",
    "#     #     print(\"Loaded SRResNet warm-up weights from:\", SRRESNET_WARMUP_PATH)\n",
    "#     # except Exception as e:\n",
    "#     #     print(\"Could not load SRResNet warm-up weights:\", e)\n",
    "#     #\n",
    "#     # # Quick sanity training run\n",
    "#     # # train_srgan_baseline(srgan_gen, srgan_disc, srgan_combined, vgg,\n",
    "#     # #                      train_gen, epochs=1, steps_per_epoch=10)\n",
    "#     #\n",
    "#     # if test_files:\n",
    "#     #     img_path = os.path.join(test_y_dir, test_files[0])\n",
    "#     #     predict_srgan_full_image(srgan_gen, img_path)\n",
    "\n",
    "#     # ---------- 3) Attentive ESRGAN ----------\n",
    "#     # att_gen = build_attentive_generator(scale=UPSCALE, num_res_blocks=16)\n",
    "#     # att_disc = build_relativistic_discriminator(input_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "#     # vgg_esr = build_vgg(hr_shape=(HR_CROP_SIZE, HR_CROP_SIZE, 3))\n",
    "#     #\n",
    "#     # try:\n",
    "#     #     att_gen.load_weights(ATTENTIVE_WARMUP_PATH)\n",
    "#     #     print(\"Loaded attentive warm-up weights from:\", ATTENTIVE_WARMUP_PATH)\n",
    "#     # except Exception as e:\n",
    "#     #     print(\"Could not load attentive warm-up weights:\", e)\n",
    "#     #\n",
    "#     # # Quick sanity training run\n",
    "#     # # train_attentive_esrgan(att_gen, att_disc, vgg_esr,\n",
    "#     # #                        train_gen, epochs=1, steps_per_epoch=10)\n",
    "#     #\n",
    "#     # if test_files:\n",
    "#     #     img_path = os.path.join(test_y_dir, test_files[0])\n",
    "#     #     predict_attentive_full_image(att_gen, img_path)\n",
    "# # "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2017696,
     "sourceId": 3342171,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8954005,
     "sourceId": 14067285,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8996072,
     "sourceId": 14120723,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9000742,
     "sourceId": 14126669,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 530115,
     "modelInstanceId": 515453,
     "sourceId": 679497,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 530140,
     "modelInstanceId": 515477,
     "sourceId": 679522,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 530237,
     "modelInstanceId": 515575,
     "sourceId": 679643,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
